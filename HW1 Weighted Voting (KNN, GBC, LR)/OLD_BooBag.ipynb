{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Denis/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.fixes import expit as sigmoid\n",
    "from sklearn.ensemble.gradient_boosting import BinomialDeviance, ZeroEstimator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASETS_PATH = '/Users/Denis/Google Диск/Datasets/'\n",
    "\n",
    "def get_train_test(X, Y, test_rate=.2):\n",
    "    idx_test = np.random.choice(Y.shape[0], Y.shape[0] * test_rate, replace=False)\n",
    "    idx_train = [i  for i in xrange(Y.shape[0]) if i not in idx_test]\n",
    "    return X[idx_train, :], Y[idx_train], X[idx_test, :], Y[idx_test]\n",
    "\n",
    "def load_wine():\n",
    "    PATH = DATASETS_PATH + 'wine/wine.data.txt'\n",
    "    M = np.loadtxt(PATH, delimiter=',')\n",
    "    return get_train_test(M[:, 1:], M[:, 0] - 1)\n",
    "\n",
    "def load_iris():\n",
    "    PATH = DATASETS_PATH + 'iris/iris.data.txt'\n",
    "    M = np.loadtxt(PATH, delimiter=',', converters={4: lambda x: \\\n",
    "                                                    ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'].index(x)})\n",
    "    return get_train_test(M[:, :-1], M[:, -1])\n",
    "\n",
    "def load_liver_disorders():\n",
    "    PATH = DATASETS_PATH + 'liver-disorders/bupa.data.txt'\n",
    "    M = np.loadtxt(PATH, delimiter=',')\n",
    "    return get_train_test(M[:, :-1], M[:, -1].astype(int) - 1)\n",
    "\n",
    "def load_spam():\n",
    "    TRAIN_PATH = DATASETS_PATH + 'spam/spam.train.txt'\n",
    "    TEST_PATH = DATASETS_PATH + 'spam/spam.test.txt'\n",
    "    M_train = np.loadtxt(TRAIN_PATH, dtype=np.float64)\n",
    "    M_test = np.loadtxt(TEST_PATH, dtype=np.float64)\n",
    "    return M_train[:, 1:], M_train[:, 0], M_test[:, 1:], M_test[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,\n",
    "                ):\n",
    "        self.is_leaf = None\n",
    "        self.feature = None\n",
    "        self.treshold = None\n",
    "        self.prediction = None\n",
    "        self.l = None\n",
    "        self.r = None\n",
    "    \n",
    "    def fit(self,\n",
    "            _X,\n",
    "            _Y,\n",
    "            _depth,\n",
    "            _min_leaf,\n",
    "            _min_impurity = 1e-7,\n",
    "           ):\n",
    "        self.is_leaf = True\n",
    "        self.prediction = _Y.mean()\n",
    "        if (_depth == 0) or (_Y.shape[0] < max(2, _min_leaf)):\n",
    "            return self\n",
    "        else:\n",
    "            splits = {}\n",
    "            for ftr in xrange(_X.shape[1]):\n",
    "                treshold, loss = self.split(_X[:, ftr].ravel(), _Y)\n",
    "                splits[(ftr, treshold)] = loss\n",
    "            if splits == {}:\n",
    "                return self\n",
    "            else:\n",
    "                self.feature, self.treshold = splits.keys()[np.argmax(splits.values())]\n",
    "                l_idx = _X[:, self.feature].ravel() < self.treshold\n",
    "                r_idx = _X[:, self.feature].ravel() >= self.treshold\n",
    "                if r_idx.sum() < _min_leaf or l_idx.sum() < _min_leaf or splits[(self.feature, self.treshold)] < _min_impurity:\n",
    "                    return self\n",
    "                self.l = Node().fit(_X[l_idx, :], _Y[l_idx],  _depth - 1, _min_leaf)\n",
    "                self.r = Node().fit(_X[r_idx, :], _Y[r_idx], _depth - 1, _min_leaf)\n",
    "                self.is_leaf = False\n",
    "\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def update_leafs(self, \n",
    "                     X, Y, \n",
    "                     antigradient, \n",
    "                    ):\n",
    "        if self.is_leaf:\n",
    "            numerator = np.sum(antigradient)\n",
    "            denominator = np.sum((Y - antigradient) * (1. - Y + antigradient))\n",
    "            if denominator == 0.0:\n",
    "                self.prediction = 0.0\n",
    "            else:\n",
    "                self.prediction = numerator / denominator\n",
    "        else:\n",
    "            idx_l = X[:, self.feature] < self.treshold\n",
    "            idx_r = X[:, self.feature] >= self.treshold\n",
    "            self.l.update_leafs(X[idx_l, :], Y[idx_l], antigradient[idx_l])\n",
    "            self.r.update_leafs(X[idx_r, :], Y[idx_r], antigradient[idx_r])\n",
    "    \n",
    "    def split(self, \n",
    "              _X,\n",
    "              _Y,\n",
    "             ):\n",
    "        \n",
    "        idx = _X.argsort()\n",
    "        X, Y = _X[idx], _Y[idx]\n",
    "        \n",
    "        best = 0\n",
    "        treshold = X[0]\n",
    "        Sl, Sr = 0, Y.sum()\n",
    "        Nl, Nr = 0, Y.shape[0]\n",
    "        for i in range(X.shape[0] - 1):\n",
    "            Sl += Y[i]\n",
    "            Sr -= Y[i]\n",
    "            Nl += 1\n",
    "            Nr -= 1\n",
    "            if (X[i + 1] > X[i]):\n",
    "                tmp = (Sl ** 2 / Nl) + (Sr ** 2 / Nr)\n",
    "                if tmp > best:\n",
    "                    best = tmp\n",
    "                    treshold = (X[i] + X[i + 1]) / 2                       \n",
    "        return treshold, best\n",
    "        \n",
    "    \n",
    "    def predict(self, \n",
    "                _X,\n",
    "               ):\n",
    "        if self.is_leaf: \n",
    "            return np.zeros(_X.shape[0]) + self.prediction\n",
    "        else:\n",
    "            Y = np.zeros((_X.shape[0],))\n",
    "            feature = _X[:, self.feature].ravel()\n",
    "            idx_l = _X[:, self.feature].ravel() < self.treshold\n",
    "            idx_r = _X[:, self.feature].ravel() >= self.treshold\n",
    "            Y_l = self.l.predict(_X[idx_l, :])\n",
    "            Y_r = self.r.predict(_X[idx_r, :])\n",
    "            Y[idx_l] = Y_l\n",
    "            Y[idx_r] = Y_r\n",
    "            return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DTRegressor:\n",
    "    def __init__(self,\n",
    "                ):\n",
    "        self.root = None\n",
    "    \n",
    "    def fit(self,\n",
    "            _X,\n",
    "            _Y,\n",
    "            _depth = 3,\n",
    "            _min_leaf = 1,\n",
    "           ):\n",
    "        self.root = Node()\n",
    "        self.root.fit(_X, _Y, _depth, _min_leaf)\n",
    "    \n",
    "    def update_leafs(self,\n",
    "                     X, Y, \n",
    "                     antigradient, \n",
    "                    ):\n",
    "        self.root.update_leafs(X, Y, antigradient)\n",
    "    \n",
    "    def predict(self,\n",
    "                      _X,\n",
    "               ):\n",
    "        return self.root.predict(_X)\n",
    "    \n",
    "    def score(self, \n",
    "              _X, \n",
    "              _Y,\n",
    "             ):\n",
    "        return accuracy_score(_Y, self.predict(_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Bagging():\n",
    "    def __init__(self,\n",
    "                ):\n",
    "        self.models = []\n",
    "        self.n_models = 0\n",
    "        pass\n",
    "    \n",
    "    def fit(self,\n",
    "            _X,\n",
    "            _Y,\n",
    "            _N = 11,\n",
    "            _basic_model = DTRegressor,\n",
    "            _args = {'_depth': 3},\n",
    "            _bag_part=.6, \n",
    "           ):\n",
    "        self.n_models = _N\n",
    "        for _ in xrange(_N):\n",
    "            idx = np.random.choice(_X.shape[0], int(_X.shape[0] * _bag_part), replace=False)\n",
    "            X, Y = _X[idx, :], _Y[idx]\n",
    "            cur_model = _basic_model()\n",
    "            cur_model.fit(X, Y, **_args)\n",
    "            self.models.append(cur_model)\n",
    "    \n",
    "    def predict(self, \n",
    "                _X\n",
    "               ):\n",
    "        res = np.zeros(_X.shape[0], dtype=float) \n",
    "        for model in self.models:\n",
    "            res += model.predict(_X)\n",
    "        return res / self.n_models\n",
    "    \n",
    "    def update_leafs(self,\n",
    "                     X, Y, \n",
    "                     Y_pred, \n",
    "                    ):\n",
    "        for model in self.models:\n",
    "            antigrad = L_log.negative_gradient(Y, Y_pred - self.predict(X) + model.predict(X))\n",
    "            model.update_leafs(X, Y, antigrad)\n",
    "    \n",
    "    def score(self, \n",
    "              _X, \n",
    "              _Y,\n",
    "             ):\n",
    "        return accuracy_score(_Y, self.predict(_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_log = BinomialDeviance(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self,\n",
    "                 _loss=L_log\n",
    "                ):\n",
    "        self.loss = _loss\n",
    "        self.models = []\n",
    "        self.learning_rate = None\n",
    "        self.losses_train = []\n",
    "        self.losses_test = []\n",
    "       \n",
    "    def fit(self, _X, _Y, \n",
    "            _basic_model=DTRegressor, \n",
    "            _args=defaultdict(),  _args_init=defaultdict(),\n",
    "            _X_val=np.array([]),  _Y_val=np.array([]), \n",
    "            _n_estimators=100, \n",
    "            _bag_part=.6, \n",
    "            _verbose=10,\n",
    "            _save_scores=True,\n",
    "            _learning_rate=.1\n",
    "           ):\n",
    "        self.learning_rate = _learning_rate\n",
    "        \n",
    "        for iteration in range(_n_estimators):\n",
    "            idx = None\n",
    "            X, Y = _X, _Y\n",
    "            Y_pred = self.decision_function(X)\n",
    "            antigradient = self.loss.negative_gradient(Y, Y_pred)\n",
    "            model = _basic_model(**_args_init)\n",
    "            model.fit(X, antigradient, **_args)\n",
    "            if _basic_model == DTRegressor:\n",
    "                model.update_leafs(X, Y, antigradient)\n",
    "            elif _basic_model == Bagging:\n",
    "                model.update_leafs(X, Y, Y_pred)\n",
    "            self.models.append(model)\n",
    "            \n",
    "            #save losses\n",
    "            self.losses_train.append(self.loss(_Y, self.decision_function(_X)))\n",
    "            self.losses_test.append(self.loss(_Y_val, self.decision_function(_X_val)))\n",
    "            if iteration % _verbose == 0:\n",
    "                print \"Iteration: %d \\t, Train loss: %.04f \\t, Test loss: %.04f \\t\"%(iteration, self.losses_train[-1],\\\n",
    "                                                                                     self.losses_test[-1], )\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, _X):\n",
    "        res = np.zeros(_X.shape[0])\n",
    "        for model in self.models:\n",
    "            res += model.predict(_X) * self.learning_rate\n",
    "        return res \n",
    "    \n",
    "    def predict_proba(self, \n",
    "                _X\n",
    "               ):\n",
    "        return sigmoid(self.decision_function(_X))\n",
    "        \n",
    "    def predict(self, \n",
    "                _X\n",
    "               ):\n",
    "        return np.array(self.predict_proba(_X) > .5, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_spam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Без бэггинга **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t, Train loss: 1.3255 \t, Test loss: 1.3413 \t\n",
      "Iteration: 1 \t, Train loss: 1.2706 \t, Test loss: 1.3011 \t\n",
      "Iteration: 2 \t, Train loss: 1.2197 \t, Test loss: 1.2669 \t\n",
      "Iteration: 3 \t, Train loss: 1.1737 \t, Test loss: 1.2329 \t\n",
      "Iteration: 4 \t, Train loss: 1.1307 \t, Test loss: 1.1981 \t\n",
      "Iteration: 5 \t, Train loss: 1.0914 \t, Test loss: 1.1648 \t\n",
      "Iteration: 6 \t, Train loss: 1.0548 \t, Test loss: 1.1413 \t\n",
      "Iteration: 7 \t, Train loss: 1.0211 \t, Test loss: 1.1064 \t\n",
      "Iteration: 8 \t, Train loss: 0.9864 \t, Test loss: 1.0900 \t\n",
      "Iteration: 9 \t, Train loss: 0.9551 \t, Test loss: 1.0563 \t\n",
      "Iteration: 10 \t, Train loss: 0.9250 \t, Test loss: 1.0416 \t\n",
      "Iteration: 11 \t, Train loss: 0.8995 \t, Test loss: 1.0166 \t\n",
      "Iteration: 12 \t, Train loss: 0.8735 \t, Test loss: 0.9885 \t\n",
      "Iteration: 13 \t, Train loss: 0.8472 \t, Test loss: 0.9814 \t\n",
      "Iteration: 14 \t, Train loss: 0.8230 \t, Test loss: 0.9765 \t\n",
      "Iteration: 15 \t, Train loss: 0.8013 \t, Test loss: 0.9584 \t\n",
      "Iteration: 16 \t, Train loss: 0.7796 \t, Test loss: 0.9605 \t\n",
      "Iteration: 17 \t, Train loss: 0.7574 \t, Test loss: 0.9401 \t\n",
      "Iteration: 18 \t, Train loss: 0.7380 \t, Test loss: 0.9129 \t\n",
      "Iteration: 19 \t, Train loss: 0.7197 \t, Test loss: 0.9020 \t\n",
      "Iteration: 20 \t, Train loss: 0.7010 \t, Test loss: 0.8867 \t\n",
      "Iteration: 21 \t, Train loss: 0.6831 \t, Test loss: 0.8672 \t\n",
      "Iteration: 22 \t, Train loss: 0.6648 \t, Test loss: 0.8458 \t\n",
      "Iteration: 23 \t, Train loss: 0.6497 \t, Test loss: 0.8319 \t\n",
      "Iteration: 24 \t, Train loss: 0.6340 \t, Test loss: 0.8174 \t\n",
      "Iteration: 25 \t, Train loss: 0.6195 \t, Test loss: 0.8016 \t\n",
      "Iteration: 26 \t, Train loss: 0.6043 \t, Test loss: 0.7784 \t\n",
      "Iteration: 27 \t, Train loss: 0.5915 \t, Test loss: 0.7659 \t\n",
      "Iteration: 28 \t, Train loss: 0.5784 \t, Test loss: 0.7500 \t\n",
      "Iteration: 29 \t, Train loss: 0.5669 \t, Test loss: 0.7428 \t\n",
      "Iteration: 30 \t, Train loss: 0.5544 \t, Test loss: 0.7228 \t\n",
      "Iteration: 31 \t, Train loss: 0.5431 \t, Test loss: 0.7138 \t\n",
      "Iteration: 32 \t, Train loss: 0.5322 \t, Test loss: 0.7042 \t\n",
      "Iteration: 33 \t, Train loss: 0.5214 \t, Test loss: 0.6864 \t\n",
      "Iteration: 34 \t, Train loss: 0.5116 \t, Test loss: 0.6760 \t\n",
      "Iteration: 35 \t, Train loss: 0.5018 \t, Test loss: 0.6648 \t\n",
      "Iteration: 36 \t, Train loss: 0.4924 \t, Test loss: 0.6551 \t\n",
      "Iteration: 37 \t, Train loss: 0.4838 \t, Test loss: 0.6470 \t\n",
      "Iteration: 38 \t, Train loss: 0.4743 \t, Test loss: 0.6380 \t\n",
      "Iteration: 39 \t, Train loss: 0.4657 \t, Test loss: 0.6257 \t\n",
      "Iteration: 40 \t, Train loss: 0.4583 \t, Test loss: 0.6212 \t\n",
      "Iteration: 41 \t, Train loss: 0.4503 \t, Test loss: 0.6087 \t\n",
      "Iteration: 42 \t, Train loss: 0.4419 \t, Test loss: 0.5999 \t\n",
      "Iteration: 43 \t, Train loss: 0.4346 \t, Test loss: 0.5946 \t\n",
      "Iteration: 44 \t, Train loss: 0.4273 \t, Test loss: 0.5828 \t\n",
      "Iteration: 45 \t, Train loss: 0.4208 \t, Test loss: 0.5745 \t\n",
      "Iteration: 46 \t, Train loss: 0.4137 \t, Test loss: 0.5673 \t\n",
      "Iteration: 47 \t, Train loss: 0.4067 \t, Test loss: 0.5629 \t\n",
      "Iteration: 48 \t, Train loss: 0.4010 \t, Test loss: 0.5576 \t\n",
      "Iteration: 49 \t, Train loss: 0.3948 \t, Test loss: 0.5459 \t\n",
      "Iteration: 50 \t, Train loss: 0.3889 \t, Test loss: 0.5404 \t\n",
      "Iteration: 51 \t, Train loss: 0.3832 \t, Test loss: 0.5386 \t\n",
      "Iteration: 52 \t, Train loss: 0.3778 \t, Test loss: 0.5332 \t\n",
      "Iteration: 53 \t, Train loss: 0.3728 \t, Test loss: 0.5266 \t\n",
      "Iteration: 54 \t, Train loss: 0.3675 \t, Test loss: 0.5243 \t\n",
      "Iteration: 55 \t, Train loss: 0.3623 \t, Test loss: 0.5181 \t\n",
      "Iteration: 56 \t, Train loss: 0.3569 \t, Test loss: 0.5107 \t\n",
      "Iteration: 57 \t, Train loss: 0.3520 \t, Test loss: 0.5062 \t\n",
      "Iteration: 58 \t, Train loss: 0.3471 \t, Test loss: 0.5025 \t\n",
      "Iteration: 59 \t, Train loss: 0.3426 \t, Test loss: 0.4959 \t\n",
      "Iteration: 60 \t, Train loss: 0.3377 \t, Test loss: 0.4904 \t\n",
      "Iteration: 61 \t, Train loss: 0.3335 \t, Test loss: 0.4895 \t\n",
      "Iteration: 62 \t, Train loss: 0.3293 \t, Test loss: 0.4830 \t\n",
      "Iteration: 63 \t, Train loss: 0.3253 \t, Test loss: 0.4798 \t\n",
      "Iteration: 64 \t, Train loss: 0.3217 \t, Test loss: 0.4759 \t\n",
      "Iteration: 65 \t, Train loss: 0.3175 \t, Test loss: 0.4708 \t\n",
      "Iteration: 66 \t, Train loss: 0.3141 \t, Test loss: 0.4686 \t\n",
      "Iteration: 67 \t, Train loss: 0.3105 \t, Test loss: 0.4696 \t\n",
      "Iteration: 68 \t, Train loss: 0.3069 \t, Test loss: 0.4646 \t\n",
      "Iteration: 69 \t, Train loss: 0.3034 \t, Test loss: 0.4606 \t\n",
      "Iteration: 70 \t, Train loss: 0.3001 \t, Test loss: 0.4573 \t\n",
      "Iteration: 71 \t, Train loss: 0.2968 \t, Test loss: 0.4548 \t\n",
      "Iteration: 72 \t, Train loss: 0.2934 \t, Test loss: 0.4505 \t\n",
      "Iteration: 73 \t, Train loss: 0.2904 \t, Test loss: 0.4471 \t\n",
      "Iteration: 74 \t, Train loss: 0.2875 \t, Test loss: 0.4436 \t\n",
      "Iteration: 75 \t, Train loss: 0.2844 \t, Test loss: 0.4385 \t\n",
      "Iteration: 76 \t, Train loss: 0.2814 \t, Test loss: 0.4351 \t\n",
      "Iteration: 77 \t, Train loss: 0.2786 \t, Test loss: 0.4287 \t\n",
      "Iteration: 78 \t, Train loss: 0.2759 \t, Test loss: 0.4257 \t\n",
      "Iteration: 79 \t, Train loss: 0.2733 \t, Test loss: 0.4248 \t\n",
      "Iteration: 80 \t, Train loss: 0.2707 \t, Test loss: 0.4214 \t\n",
      "Iteration: 81 \t, Train loss: 0.2684 \t, Test loss: 0.4187 \t\n",
      "Iteration: 82 \t, Train loss: 0.2658 \t, Test loss: 0.4171 \t\n",
      "Iteration: 83 \t, Train loss: 0.2635 \t, Test loss: 0.4143 \t\n",
      "Iteration: 84 \t, Train loss: 0.2610 \t, Test loss: 0.4113 \t\n",
      "Iteration: 85 \t, Train loss: 0.2586 \t, Test loss: 0.4057 \t\n",
      "Iteration: 86 \t, Train loss: 0.2562 \t, Test loss: 0.4047 \t\n",
      "Iteration: 87 \t, Train loss: 0.2539 \t, Test loss: 0.4031 \t\n",
      "Iteration: 88 \t, Train loss: 0.2516 \t, Test loss: 0.4040 \t\n",
      "Iteration: 89 \t, Train loss: 0.2495 \t, Test loss: 0.4020 \t\n",
      "Iteration: 90 \t, Train loss: 0.2474 \t, Test loss: 0.4023 \t\n",
      "Iteration: 91 \t, Train loss: 0.2450 \t, Test loss: 0.4005 \t\n",
      "Iteration: 92 \t, Train loss: 0.2432 \t, Test loss: 0.3996 \t\n",
      "Iteration: 93 \t, Train loss: 0.2414 \t, Test loss: 0.3982 \t\n",
      "Iteration: 94 \t, Train loss: 0.2396 \t, Test loss: 0.3950 \t\n",
      "Iteration: 95 \t, Train loss: 0.2372 \t, Test loss: 0.3910 \t\n",
      "Iteration: 96 \t, Train loss: 0.2351 \t, Test loss: 0.3863 \t\n",
      "Iteration: 97 \t, Train loss: 0.2332 \t, Test loss: 0.3844 \t\n",
      "Iteration: 98 \t, Train loss: 0.2315 \t, Test loss: 0.3834 \t\n",
      "Iteration: 99 \t, Train loss: 0.2299 \t, Test loss: 0.3815 \t\n",
      "Iteration: 100 \t, Train loss: 0.2283 \t, Test loss: 0.3806 \t\n",
      "Iteration: 101 \t, Train loss: 0.2263 \t, Test loss: 0.3783 \t\n",
      "Iteration: 102 \t, Train loss: 0.2247 \t, Test loss: 0.3791 \t\n",
      "Iteration: 103 \t, Train loss: 0.2233 \t, Test loss: 0.3784 \t\n",
      "Iteration: 104 \t, Train loss: 0.2216 \t, Test loss: 0.3793 \t\n",
      "Iteration: 105 \t, Train loss: 0.2200 \t, Test loss: 0.3768 \t\n",
      "Iteration: 106 \t, Train loss: 0.2183 \t, Test loss: 0.3736 \t\n",
      "Iteration: 107 \t, Train loss: 0.2166 \t, Test loss: 0.3713 \t\n",
      "Iteration: 108 \t, Train loss: 0.2151 \t, Test loss: 0.3694 \t\n",
      "Iteration: 109 \t, Train loss: 0.2136 \t, Test loss: 0.3687 \t\n",
      "Iteration: 110 \t, Train loss: 0.2119 \t, Test loss: 0.3698 \t\n",
      "Iteration: 111 \t, Train loss: 0.2106 \t, Test loss: 0.3688 \t\n",
      "Iteration: 112 \t, Train loss: 0.2090 \t, Test loss: 0.3667 \t\n",
      "Iteration: 113 \t, Train loss: 0.2075 \t, Test loss: 0.3648 \t\n",
      "Iteration: 114 \t, Train loss: 0.2060 \t, Test loss: 0.3608 \t\n",
      "Iteration: 115 \t, Train loss: 0.2046 \t, Test loss: 0.3596 \t\n",
      "Iteration: 116 \t, Train loss: 0.2033 \t, Test loss: 0.3581 \t\n",
      "Iteration: 117 \t, Train loss: 0.2021 \t, Test loss: 0.3599 \t\n",
      "Iteration: 118 \t, Train loss: 0.2008 \t, Test loss: 0.3588 \t\n",
      "Iteration: 119 \t, Train loss: 0.1997 \t, Test loss: 0.3578 \t\n",
      "Iteration: 120 \t, Train loss: 0.1983 \t, Test loss: 0.3560 \t\n",
      "Iteration: 121 \t, Train loss: 0.1971 \t, Test loss: 0.3546 \t\n",
      "Iteration: 122 \t, Train loss: 0.1959 \t, Test loss: 0.3523 \t\n",
      "Iteration: 123 \t, Train loss: 0.1948 \t, Test loss: 0.3510 \t\n",
      "Iteration: 124 \t, Train loss: 0.1939 \t, Test loss: 0.3508 \t\n",
      "Iteration: 125 \t, Train loss: 0.1927 \t, Test loss: 0.3499 \t\n",
      "Iteration: 126 \t, Train loss: 0.1916 \t, Test loss: 0.3489 \t\n",
      "Iteration: 127 \t, Train loss: 0.1902 \t, Test loss: 0.3476 \t\n",
      "Iteration: 128 \t, Train loss: 0.1891 \t, Test loss: 0.3466 \t\n",
      "Iteration: 129 \t, Train loss: 0.1882 \t, Test loss: 0.3458 \t\n",
      "Iteration: 130 \t, Train loss: 0.1869 \t, Test loss: 0.3464 \t\n",
      "Iteration: 131 \t, Train loss: 0.1856 \t, Test loss: 0.3445 \t\n",
      "Iteration: 132 \t, Train loss: 0.1844 \t, Test loss: 0.3435 \t\n",
      "Iteration: 133 \t, Train loss: 0.1834 \t, Test loss: 0.3420 \t\n",
      "Iteration: 134 \t, Train loss: 0.1824 \t, Test loss: 0.3404 \t\n",
      "Iteration: 135 \t, Train loss: 0.1816 \t, Test loss: 0.3391 \t\n",
      "Iteration: 136 \t, Train loss: 0.1806 \t, Test loss: 0.3410 \t\n",
      "Iteration: 137 \t, Train loss: 0.1794 \t, Test loss: 0.3394 \t\n",
      "Iteration: 138 \t, Train loss: 0.1785 \t, Test loss: 0.3380 \t\n",
      "Iteration: 139 \t, Train loss: 0.1776 \t, Test loss: 0.3374 \t\n",
      "Iteration: 140 \t, Train loss: 0.1767 \t, Test loss: 0.3367 \t\n",
      "Iteration: 141 \t, Train loss: 0.1756 \t, Test loss: 0.3378 \t\n",
      "Iteration: 142 \t, Train loss: 0.1747 \t, Test loss: 0.3369 \t\n",
      "Iteration: 143 \t, Train loss: 0.1739 \t, Test loss: 0.3358 \t\n",
      "Iteration: 144 \t, Train loss: 0.1728 \t, Test loss: 0.3384 \t\n",
      "Iteration: 145 \t, Train loss: 0.1720 \t, Test loss: 0.3381 \t\n",
      "Iteration: 146 \t, Train loss: 0.1713 \t, Test loss: 0.3362 \t\n",
      "Iteration: 147 \t, Train loss: 0.1703 \t, Test loss: 0.3374 \t\n",
      "Iteration: 148 \t, Train loss: 0.1692 \t, Test loss: 0.3349 \t\n",
      "Iteration: 149 \t, Train loss: 0.1683 \t, Test loss: 0.3331 \t\n",
      "Iteration: 150 \t, Train loss: 0.1673 \t, Test loss: 0.3324 \t\n",
      "Iteration: 151 \t, Train loss: 0.1666 \t, Test loss: 0.3317 \t\n",
      "Iteration: 152 \t, Train loss: 0.1656 \t, Test loss: 0.3303 \t\n",
      "Iteration: 153 \t, Train loss: 0.1650 \t, Test loss: 0.3299 \t\n",
      "Iteration: 154 \t, Train loss: 0.1640 \t, Test loss: 0.3284 \t\n",
      "Iteration: 155 \t, Train loss: 0.1632 \t, Test loss: 0.3262 \t\n",
      "Iteration: 156 \t, Train loss: 0.1622 \t, Test loss: 0.3271 \t\n",
      "Iteration: 157 \t, Train loss: 0.1615 \t, Test loss: 0.3276 \t\n",
      "Iteration: 158 \t, Train loss: 0.1610 \t, Test loss: 0.3284 \t\n",
      "Iteration: 159 \t, Train loss: 0.1599 \t, Test loss: 0.3269 \t\n",
      "Iteration: 160 \t, Train loss: 0.1592 \t, Test loss: 0.3257 \t\n",
      "Iteration: 161 \t, Train loss: 0.1586 \t, Test loss: 0.3253 \t\n",
      "Iteration: 162 \t, Train loss: 0.1579 \t, Test loss: 0.3251 \t\n",
      "Iteration: 163 \t, Train loss: 0.1570 \t, Test loss: 0.3244 \t\n",
      "Iteration: 164 \t, Train loss: 0.1564 \t, Test loss: 0.3262 \t\n",
      "Iteration: 165 \t, Train loss: 0.1561 \t, Test loss: 0.3262 \t\n",
      "Iteration: 166 \t, Train loss: 0.1553 \t, Test loss: 0.3246 \t\n",
      "Iteration: 167 \t, Train loss: 0.1546 \t, Test loss: 0.3232 \t\n",
      "Iteration: 168 \t, Train loss: 0.1540 \t, Test loss: 0.3220 \t\n",
      "Iteration: 169 \t, Train loss: 0.1534 \t, Test loss: 0.3218 \t\n",
      "Iteration: 170 \t, Train loss: 0.1529 \t, Test loss: 0.3215 \t\n",
      "Iteration: 171 \t, Train loss: 0.1522 \t, Test loss: 0.3194 \t\n",
      "Iteration: 172 \t, Train loss: 0.1516 \t, Test loss: 0.3188 \t\n",
      "Iteration: 173 \t, Train loss: 0.1508 \t, Test loss: 0.3194 \t\n",
      "Iteration: 174 \t, Train loss: 0.1499 \t, Test loss: 0.3180 \t\n",
      "Iteration: 175 \t, Train loss: 0.1491 \t, Test loss: 0.3166 \t\n",
      "Iteration: 176 \t, Train loss: 0.1485 \t, Test loss: 0.3158 \t\n",
      "Iteration: 177 \t, Train loss: 0.1478 \t, Test loss: 0.3147 \t\n",
      "Iteration: 178 \t, Train loss: 0.1474 \t, Test loss: 0.3142 \t\n",
      "Iteration: 179 \t, Train loss: 0.1466 \t, Test loss: 0.3129 \t\n",
      "Iteration: 180 \t, Train loss: 0.1463 \t, Test loss: 0.3120 \t\n",
      "Iteration: 181 \t, Train loss: 0.1456 \t, Test loss: 0.3108 \t\n",
      "Iteration: 182 \t, Train loss: 0.1451 \t, Test loss: 0.3106 \t\n",
      "Iteration: 183 \t, Train loss: 0.1444 \t, Test loss: 0.3102 \t\n",
      "Iteration: 184 \t, Train loss: 0.1440 \t, Test loss: 0.3113 \t\n",
      "Iteration: 185 \t, Train loss: 0.1435 \t, Test loss: 0.3109 \t\n",
      "Iteration: 186 \t, Train loss: 0.1430 \t, Test loss: 0.3098 \t\n",
      "Iteration: 187 \t, Train loss: 0.1424 \t, Test loss: 0.3098 \t\n",
      "Iteration: 188 \t, Train loss: 0.1416 \t, Test loss: 0.3092 \t\n",
      "Iteration: 189 \t, Train loss: 0.1410 \t, Test loss: 0.3086 \t\n",
      "Iteration: 190 \t, Train loss: 0.1404 \t, Test loss: 0.3075 \t\n",
      "Iteration: 191 \t, Train loss: 0.1398 \t, Test loss: 0.3064 \t\n",
      "Iteration: 192 \t, Train loss: 0.1395 \t, Test loss: 0.3066 \t\n",
      "Iteration: 193 \t, Train loss: 0.1391 \t, Test loss: 0.3063 \t\n",
      "Iteration: 194 \t, Train loss: 0.1384 \t, Test loss: 0.3056 \t\n",
      "Iteration: 195 \t, Train loss: 0.1380 \t, Test loss: 0.3052 \t\n",
      "Iteration: 196 \t, Train loss: 0.1376 \t, Test loss: 0.3035 \t\n",
      "Iteration: 197 \t, Train loss: 0.1372 \t, Test loss: 0.3036 \t\n",
      "Iteration: 198 \t, Train loss: 0.1364 \t, Test loss: 0.3024 \t\n",
      "Iteration: 199 \t, Train loss: 0.1360 \t, Test loss: 0.3021 \t\n",
      "Iteration: 200 \t, Train loss: 0.1357 \t, Test loss: 0.3031 \t\n",
      "Iteration: 201 \t, Train loss: 0.1353 \t, Test loss: 0.3034 \t\n",
      "Iteration: 202 \t, Train loss: 0.1351 \t, Test loss: 0.3032 \t\n",
      "Iteration: 203 \t, Train loss: 0.1347 \t, Test loss: 0.3024 \t\n",
      "Iteration: 204 \t, Train loss: 0.1342 \t, Test loss: 0.3017 \t\n",
      "Iteration: 205 \t, Train loss: 0.1339 \t, Test loss: 0.3017 \t\n",
      "Iteration: 206 \t, Train loss: 0.1334 \t, Test loss: 0.3010 \t\n",
      "Iteration: 207 \t, Train loss: 0.1330 \t, Test loss: 0.3002 \t\n",
      "Iteration: 208 \t, Train loss: 0.1325 \t, Test loss: 0.2997 \t\n",
      "Iteration: 209 \t, Train loss: 0.1322 \t, Test loss: 0.2998 \t\n",
      "Iteration: 210 \t, Train loss: 0.1318 \t, Test loss: 0.2992 \t\n",
      "Iteration: 211 \t, Train loss: 0.1314 \t, Test loss: 0.2987 \t\n",
      "Iteration: 212 \t, Train loss: 0.1310 \t, Test loss: 0.2981 \t\n",
      "Iteration: 213 \t, Train loss: 0.1307 \t, Test loss: 0.2970 \t\n",
      "Iteration: 214 \t, Train loss: 0.1304 \t, Test loss: 0.2969 \t\n",
      "Iteration: 215 \t, Train loss: 0.1298 \t, Test loss: 0.2976 \t\n",
      "Iteration: 216 \t, Train loss: 0.1294 \t, Test loss: 0.2985 \t\n",
      "Iteration: 217 \t, Train loss: 0.1290 \t, Test loss: 0.2981 \t\n",
      "Iteration: 218 \t, Train loss: 0.1286 \t, Test loss: 0.2975 \t\n",
      "Iteration: 219 \t, Train loss: 0.1283 \t, Test loss: 0.2970 \t\n",
      "Iteration: 220 \t, Train loss: 0.1279 \t, Test loss: 0.2970 \t\n",
      "Iteration: 221 \t, Train loss: 0.1272 \t, Test loss: 0.2958 \t\n",
      "Iteration: 222 \t, Train loss: 0.1266 \t, Test loss: 0.2965 \t\n",
      "Iteration: 223 \t, Train loss: 0.1261 \t, Test loss: 0.2957 \t\n",
      "Iteration: 224 \t, Train loss: 0.1257 \t, Test loss: 0.2953 \t\n",
      "Iteration: 225 \t, Train loss: 0.1252 \t, Test loss: 0.2939 \t\n",
      "Iteration: 226 \t, Train loss: 0.1247 \t, Test loss: 0.2932 \t\n",
      "Iteration: 227 \t, Train loss: 0.1244 \t, Test loss: 0.2937 \t\n",
      "Iteration: 228 \t, Train loss: 0.1240 \t, Test loss: 0.2934 \t\n",
      "Iteration: 229 \t, Train loss: 0.1236 \t, Test loss: 0.2933 \t\n",
      "Iteration: 230 \t, Train loss: 0.1234 \t, Test loss: 0.2931 \t\n",
      "Iteration: 231 \t, Train loss: 0.1232 \t, Test loss: 0.2927 \t\n",
      "Iteration: 232 \t, Train loss: 0.1227 \t, Test loss: 0.2921 \t\n",
      "Iteration: 233 \t, Train loss: 0.1223 \t, Test loss: 0.2916 \t\n",
      "Iteration: 234 \t, Train loss: 0.1220 \t, Test loss: 0.2911 \t\n",
      "Iteration: 235 \t, Train loss: 0.1215 \t, Test loss: 0.2903 \t\n",
      "Iteration: 236 \t, Train loss: 0.1211 \t, Test loss: 0.2900 \t\n",
      "Iteration: 237 \t, Train loss: 0.1209 \t, Test loss: 0.2895 \t\n",
      "Iteration: 238 \t, Train loss: 0.1206 \t, Test loss: 0.2889 \t\n",
      "Iteration: 239 \t, Train loss: 0.1201 \t, Test loss: 0.2889 \t\n",
      "Iteration: 240 \t, Train loss: 0.1198 \t, Test loss: 0.2885 \t\n",
      "Iteration: 241 \t, Train loss: 0.1193 \t, Test loss: 0.2878 \t\n",
      "Iteration: 242 \t, Train loss: 0.1188 \t, Test loss: 0.2868 \t\n",
      "Iteration: 243 \t, Train loss: 0.1185 \t, Test loss: 0.2877 \t\n",
      "Iteration: 244 \t, Train loss: 0.1183 \t, Test loss: 0.2878 \t\n",
      "Iteration: 245 \t, Train loss: 0.1181 \t, Test loss: 0.2878 \t\n",
      "Iteration: 246 \t, Train loss: 0.1177 \t, Test loss: 0.2871 \t\n",
      "Iteration: 247 \t, Train loss: 0.1174 \t, Test loss: 0.2864 \t\n",
      "Iteration: 248 \t, Train loss: 0.1170 \t, Test loss: 0.2873 \t\n",
      "Iteration: 249 \t, Train loss: 0.1166 \t, Test loss: 0.2870 \t\n",
      "0.961913285601\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoosting()\n",
    "clf.fit(X_train, Y_train, _X_val=X_test, _Y_val=Y_test, _n_estimators = 250, _learning_rate=0.05, _verbose = 1)\n",
    "print accuracy_score(clf.predict(X_test).round(), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sklearn **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3255            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         2           1.2706            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         3           1.2197            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4           1.1737            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         5           1.1307            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         6           1.0914            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         7           1.0548            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         8           1.0211            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         9           0.9864            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        10           0.9551            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        11           0.9250            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        12           0.8995            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        13           0.8735            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        14           0.8472            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        15           0.8230            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        16           0.8013            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        17           0.7796            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        18           0.7574            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        19           0.7380            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        20           0.7197            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        21           0.7010            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        22           0.6831            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        23           0.6648            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        24           0.6497            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        25           0.6340            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        26           0.6195            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        27           0.6043            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        28           0.5915            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        29           0.5784            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        30           0.5669            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        31           0.5544            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        32           0.5431            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        33           0.5322            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        34           0.5214            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        35           0.5116            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        36           0.5018            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        37           0.4924            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        38           0.4838            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        39           0.4743            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        40           0.4657            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        41           0.4583            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        42           0.4503            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        43           0.4419            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        44           0.4346            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        45           0.4273            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        46           0.4208            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        47           0.4137            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        48           0.4067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        49           0.4010            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        50           0.3948            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        51           0.3889            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        52           0.3832            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        53           0.3778            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        54           0.3728            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        55           0.3675            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        56           0.3623            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        57           0.3569            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        58           0.3520            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        59           0.3471            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        60           0.3426            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        61           0.3377            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        62           0.3335            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        63           0.3293            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        64           0.3253            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        65           0.3217            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        66           0.3175            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        67           0.3141            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        68           0.3105            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        69           0.3069            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        70           0.3034            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        71           0.3001            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        72           0.2968            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        73           0.2934            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        74           0.2904            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        75           0.2875            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        76           0.2844            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        77           0.2814            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        78           0.2786            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        79           0.2759            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        80           0.2733            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        81           0.2707            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        82           0.2684            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        83           0.2658            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        84           0.2635            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        85           0.2610            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        86           0.2586            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        87           0.2562            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        88           0.2539            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        89           0.2516            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        90           0.2495            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        91           0.2474            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        92           0.2450            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        93           0.2432            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        94           0.2414            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        95           0.2396            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        96           0.2372            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        97           0.2351            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        98           0.2332            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        99           0.2315            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       100           0.2299            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       101           0.2283            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       102           0.2263            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       103           0.2247            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       104           0.2233            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       105           0.2216            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       106           0.2200            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       107           0.2183            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       108           0.2166            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       109           0.2151            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       110           0.2136            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       111           0.2119            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       112           0.2106            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       113           0.2090            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       114           0.2075            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       115           0.2060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       116           0.2046            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       117           0.2033            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       118           0.2021            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       119           0.2008            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       120           0.1997            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       121           0.1983            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       122           0.1971            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       123           0.1959            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       124           0.1948            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       125           0.1939            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       126           0.1927            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       127           0.1916            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       128           0.1902            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       129           0.1891            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       130           0.1882            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       131           0.1869            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       132           0.1856            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       133           0.1844            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       134           0.1834            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       135           0.1824            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       136           0.1816            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       137           0.1806            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       138           0.1794            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       139           0.1785            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       140           0.1776            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       141           0.1767            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       142           0.1756            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       143           0.1747            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       144           0.1739            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       145           0.1728            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       146           0.1720            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       147           0.1713            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       148           0.1703            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       149           0.1692            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       150           0.1683            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       151           0.1673            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       152           0.1666            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       153           0.1656            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       154           0.1650            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       155           0.1640            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       156           0.1632            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       157           0.1622            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       158           0.1615            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       159           0.1610            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       160           0.1599            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       161           0.1592            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       162           0.1586            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       163           0.1579            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       164           0.1570            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       165           0.1564            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       166           0.1561            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       167           0.1553            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       168           0.1546            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       169           0.1540            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       170           0.1534            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       171           0.1529            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       172           0.1522            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       173           0.1516            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       174           0.1508            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       175           0.1499            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       176           0.1491            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       177           0.1485            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       178           0.1478            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       179           0.1474            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       180           0.1466            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       181           0.1463            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       182           0.1456            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       183           0.1451            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       184           0.1444            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       185           0.1440            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       186           0.1435            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       187           0.1430            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       188           0.1424            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       189           0.1416            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       190           0.1410            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       191           0.1404            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       192           0.1398            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       193           0.1395            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       194           0.1391            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       195           0.1384            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       196           0.1380            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       197           0.1376            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       198           0.1372            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       199           0.1364            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       200           0.1360            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       201           0.1357            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       202           0.1353            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       203           0.1349            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       204           0.1346            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       205           0.1344            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       206           0.1340            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       207           0.1335            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       208           0.1332            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       209           0.1327            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       210           0.1322            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       211           0.1317            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       212           0.1313            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       213           0.1310            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       214           0.1306            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       215           0.1303            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       216           0.1301            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       217           0.1296            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       218           0.1290            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       219           0.1285            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       220           0.1281            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       221           0.1278            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       222           0.1274            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       223           0.1269            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       224           0.1265            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       225           0.1263            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       226           0.1258            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       227           0.1252            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       228           0.1248            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       229           0.1244            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       230           0.1241            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       231           0.1238            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       232           0.1235            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       233           0.1231            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       234           0.1227            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       235           0.1223            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       236           0.1220            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       237           0.1217            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       238           0.1212            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       239           0.1209            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       240           0.1206            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       241           0.1203            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       242           0.1201            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       243           0.1197            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       244           0.1195            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       245           0.1192            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       246           0.1188            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       247           0.1186            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       248           0.1184            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       249           0.1180            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       250           0.1175            0.00s\n"
     ]
    }
   ],
   "source": [
    "skl_losses = []\n",
    "skl_clf = GradientBoostingClassifier(learning_rate=.05, n_estimators=1, random_state=np.random.mtrand.RandomState(17), \\\n",
    "                                     init=ZeroEstimator(), verbose=1, warm_start=True)\n",
    "\n",
    "for i in range(250):\n",
    "    skl_clf.fit(X_train, Y_train)\n",
    "    skl_clf.n_estimators += 1\n",
    "    skl_losses.append(L_log(Y_test, skl_clf.decision_function(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Графики **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAJPCAYAAAA9sTYbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d95ec10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(skl_losses[:300], 'g')\n",
    "#plt.plot(1.03*np.array(skl_losses[:300]),'r')\n",
    "plt.plot(clf.losses_test, 'b+')\n",
    "#plt.plot(clf_bag.losses_test, 'mo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** sklearn **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2679            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         2           1.1691            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         3           1.0866            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4           1.0155            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         5           0.9485            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         6           0.8917            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         7           0.8416            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         8           0.7935            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         9           0.7546            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        10           0.7165            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        11           0.6794            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        12           0.6461            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        13           0.6139            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        14           0.5883            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        15           0.5626            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        16           0.5393            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        17           0.5189            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        18           0.4979            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        19           0.4794            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        20           0.4621            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        21           0.4468            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        22           0.4317            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        23           0.4185            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        24           0.4067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        25           0.3941            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        26           0.3832            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        27           0.3723            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        28           0.3628            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        29           0.3531            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        30           0.3442            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        31           0.3352            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        32           0.3260            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        33           0.3180            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        34           0.3107            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        35           0.3033            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        36           0.2969            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        37           0.2905            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        38           0.2848            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        39           0.2791            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        40           0.2738            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        41           0.2686            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        42           0.2628            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        43           0.2582            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        44           0.2536            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        45           0.2500            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        46           0.2455            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        47           0.2410            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        48           0.2367            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        49           0.2326            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        50           0.2287            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        51           0.2255            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        52           0.2228            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        53           0.2187            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        54           0.2153            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        55           0.2127            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        56           0.2099            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        57           0.2068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        58           0.2043            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        59           0.2013            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        60           0.1989            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        61           0.1961            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        62           0.1936            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        63           0.1910            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        64           0.1888            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        65           0.1867            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        66           0.1844            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        67           0.1820            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        68           0.1795            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        69           0.1775            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        70           0.1757            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        71           0.1737            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        72           0.1721            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        73           0.1703            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        74           0.1685            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        75           0.1672            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        76           0.1657            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        77           0.1636            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        78           0.1624            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        79           0.1607            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        80           0.1598            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        81           0.1587            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        82           0.1564            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        83           0.1550            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        84           0.1542            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        85           0.1530            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        86           0.1517            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        87           0.1504            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        88           0.1487            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        89           0.1474            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        90           0.1454            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        91           0.1443            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        92           0.1429            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        93           0.1417            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        94           0.1409            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        95           0.1397            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        96           0.1388            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        97           0.1371            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        98           0.1360            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        99           0.1345            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       100           0.1338            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       101           0.1327            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       102           0.1318            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       103           0.1309            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       104           0.1298            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       105           0.1294            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       106           0.1285            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       107           0.1275            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       108           0.1261            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       109           0.1254            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       110           0.1250            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       111           0.1242            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       112           0.1230            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       113           0.1226            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       114           0.1217            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       115           0.1212            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       116           0.1206            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       117           0.1197            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       118           0.1189            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       119           0.1179            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       120           0.1177            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       121           0.1169            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       122           0.1158            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       123           0.1151            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       124           0.1144            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       125           0.1138            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       126           0.1131            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       127           0.1125            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       128           0.1118            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       129           0.1111            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       130           0.1103            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       131           0.1099            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       132           0.1093            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       133           0.1089            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       134           0.1084            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       135           0.1077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       136           0.1073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       137           0.1067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       138           0.1060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       139           0.1051            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       140           0.1048            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       141           0.1044            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       142           0.1039            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       143           0.1035            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       144           0.1031            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       145           0.1024            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       146           0.1020            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       147           0.1015            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       148           0.1010            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       149           0.1007            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       150           0.1003            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       151           0.0997            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       152           0.0991            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       153           0.0987            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       154           0.0984            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       155           0.0979            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       156           0.0976            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       157           0.0972            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       158           0.0967            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       159           0.0963            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       160           0.0958            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       161           0.0955            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       162           0.0947            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       163           0.0942            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       164           0.0940            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       165           0.0935            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       166           0.0931            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       167           0.0926            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       168           0.0919            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       169           0.0916            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       170           0.0911            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       171           0.0907            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       172           0.0904            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       173           0.0899            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       174           0.0896            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       175           0.0891            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       176           0.0887            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       177           0.0880            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       178           0.0878            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       179           0.0874            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       180           0.0871            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       181           0.0868            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       182           0.0867            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       183           0.0861            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       184           0.0856            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       185           0.0854            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       186           0.0849            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       187           0.0843            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       188           0.0842            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       189           0.0837            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       190           0.0834            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       191           0.0830            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       192           0.0824            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       193           0.0823            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       194           0.0817            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       195           0.0814            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       196           0.0811            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       197           0.0808            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       198           0.0804            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       199           0.0801            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       200           0.0796            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       201           0.0794            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       202           0.0790            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       203           0.0785            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       204           0.0781            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       205           0.0778            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       206           0.0773            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       207           0.0769            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       208           0.0765            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       209           0.0763            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       210           0.0761            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       211           0.0755            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       212           0.0752            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       213           0.0748            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       214           0.0747            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       215           0.0744            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       216           0.0738            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       217           0.0732            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       218           0.0731            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       219           0.0726            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       220           0.0722            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       221           0.0718            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       222           0.0713            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       223           0.0712            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       224           0.0706            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       225           0.0705            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       226           0.0702            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       227           0.0699            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       228           0.0697            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       229           0.0695            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       230           0.0693            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       231           0.0690            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       232           0.0687            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       233           0.0685            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       234           0.0681            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       235           0.0679            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       236           0.0675            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       237           0.0673            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       238           0.0669            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       239           0.0665            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       240           0.0663            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       241           0.0658            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       242           0.0654            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       243           0.0652            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       244           0.0647            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       245           0.0645            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       246           0.0642            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       247           0.0638            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       248           0.0637            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       249           0.0635            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       250           0.0632            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       251           0.0630            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       252           0.0627            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       253           0.0625            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       254           0.0622            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       255           0.0618            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       256           0.0615            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       257           0.0612            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       258           0.0611            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       259           0.0607            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       260           0.0603            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       261           0.0602            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       262           0.0600            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       263           0.0597            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       264           0.0596            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       265           0.0592            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       266           0.0590            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       267           0.0589            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       268           0.0587            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       269           0.0585            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       270           0.0582            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       271           0.0579            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       272           0.0578            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       273           0.0575            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       274           0.0572            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       275           0.0568            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       276           0.0566            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       277           0.0565            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       278           0.0564            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       279           0.0561            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       280           0.0557            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       281           0.0556            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       282           0.0552            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       283           0.0551            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       284           0.0549            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       285           0.0549            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       286           0.0546            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       287           0.0545            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       288           0.0541            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       289           0.0540            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       290           0.0537            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       291           0.0534            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       292           0.0533            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       293           0.0531            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       294           0.0529            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       295           0.0527            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       296           0.0527            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       297           0.0526            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       298           0.0524            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       299           0.0521            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       300           0.0520            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       301           0.0518            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       302           0.0516            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       303           0.0513            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       304           0.0511            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       305           0.0509            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       306           0.0508            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       307           0.0505            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       308           0.0502            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       309           0.0500            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       310           0.0496            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       311           0.0495            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       312           0.0493            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       313           0.0492            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       314           0.0489            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       315           0.0487            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       316           0.0485            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       317           0.0482            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       318           0.0480            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       319           0.0477            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       320           0.0477            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       321           0.0476            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       322           0.0475            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       323           0.0474            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       324           0.0472            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       325           0.0469            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       326           0.0468            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       327           0.0467            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       328           0.0464            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       329           0.0463            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       330           0.0460            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       331           0.0458            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       332           0.0456            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       333           0.0454            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       334           0.0453            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       335           0.0451            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       336           0.0451            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       337           0.0450            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       338           0.0449            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       339           0.0447            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       340           0.0444            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       341           0.0443            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       342           0.0441            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       343           0.0439            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       344           0.0438            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       345           0.0437            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       346           0.0435            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       347           0.0433            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       348           0.0431            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       349           0.0429            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       350           0.0427            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       351           0.0426            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       352           0.0425            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       353           0.0425            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       354           0.0424            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       355           0.0423            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       356           0.0422            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       357           0.0420            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       358           0.0417            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       359           0.0416            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       360           0.0412            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       361           0.0410            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       362           0.0408            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       363           0.0407            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       364           0.0406            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       365           0.0406            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       366           0.0404            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       367           0.0403            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       368           0.0402            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       369           0.0400            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       370           0.0397            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       371           0.0396            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       372           0.0396            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       373           0.0395            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       374           0.0394            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       375           0.0392            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       376           0.0390            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       377           0.0388            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       378           0.0387            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       379           0.0386            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       380           0.0385            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       381           0.0384            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       382           0.0383            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       383           0.0380            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       384           0.0378            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       385           0.0377            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       386           0.0375            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       387           0.0374            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       388           0.0371            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       389           0.0369            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       390           0.0369            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       391           0.0368            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       392           0.0367            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       393           0.0366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       394           0.0365            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       395           0.0364            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       396           0.0363            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       397           0.0361            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       398           0.0359            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       399           0.0358            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       400           0.0356            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       401           0.0355            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       402           0.0354            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       403           0.0352            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       404           0.0352            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       405           0.0350            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       406           0.0348            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       407           0.0346            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       408           0.0346            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       409           0.0345            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       410           0.0343            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       411           0.0342            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       412           0.0342            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       413           0.0340            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       414           0.0338            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       415           0.0337            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       416           0.0336            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       417           0.0335            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       418           0.0334            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       419           0.0333            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       420           0.0332            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       421           0.0331            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       422           0.0329            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       423           0.0328            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       424           0.0326            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       425           0.0325            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       426           0.0324            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       427           0.0324            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       428           0.0322            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       429           0.0321            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       430           0.0320            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       431           0.0319            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       432           0.0317            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       433           0.0316            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       434           0.0316            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       435           0.0315            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       436           0.0314            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       437           0.0313            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       438           0.0311            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       439           0.0310            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       440           0.0309            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       441           0.0309            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       442           0.0308            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       443           0.0306            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       444           0.0305            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       445           0.0305            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       446           0.0304            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       447           0.0303            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       448           0.0303            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       449           0.0302            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       450           0.0301            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       451           0.0300            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       452           0.0299            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       453           0.0298            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       454           0.0298            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       455           0.0297            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       456           0.0296            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       457           0.0295            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       458           0.0293            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       459           0.0292            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       460           0.0290            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       461           0.0289            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       462           0.0288            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       463           0.0287            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       464           0.0286            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       465           0.0285            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       466           0.0284            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       467           0.0283            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       468           0.0281            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       469           0.0281            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       470           0.0280            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       471           0.0280            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       472           0.0279            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       473           0.0278            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       474           0.0277            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       475           0.0275            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       476           0.0275            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       477           0.0274            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       478           0.0274            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       479           0.0272            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       480           0.0271            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       481           0.0271            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       482           0.0269            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       483           0.0268            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       484           0.0267            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       485           0.0265            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       486           0.0263            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       487           0.0262            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       488           0.0261            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       489           0.0261            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       490           0.0259            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       491           0.0258            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       492           0.0257            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       493           0.0256            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       494           0.0256            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       495           0.0255            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       496           0.0254            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       497           0.0253            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       498           0.0253            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       499           0.0252            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       500           0.0251            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       501           0.0250            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       502           0.0248            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       503           0.0247            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       504           0.0247            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       505           0.0246            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       506           0.0246            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       507           0.0245            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       508           0.0244            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       509           0.0244            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       510           0.0242            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       511           0.0241            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       512           0.0240            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       513           0.0240            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       514           0.0239            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       515           0.0238            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       516           0.0237            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       517           0.0236            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       518           0.0235            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       519           0.0234            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       520           0.0233            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       521           0.0233            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       522           0.0232            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       523           0.0231            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       524           0.0230            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       525           0.0229            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       526           0.0228            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       527           0.0227            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       528           0.0226            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       529           0.0226            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       530           0.0225            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       531           0.0223            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       532           0.0223            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       533           0.0222            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       534           0.0222            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       535           0.0221            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       536           0.0219            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       537           0.0219            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       538           0.0218            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       539           0.0218            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       540           0.0217            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       541           0.0216            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       542           0.0216            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       543           0.0215            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       544           0.0215            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       545           0.0214            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       546           0.0214            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       547           0.0214            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       548           0.0213            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       549           0.0212            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       550           0.0212            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       551           0.0212            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       552           0.0211            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       553           0.0211            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       554           0.0210            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       555           0.0209            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       556           0.0208            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       557           0.0207            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       558           0.0207            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       559           0.0206            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       560           0.0205            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       561           0.0205            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       562           0.0204            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       563           0.0203            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       564           0.0202            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       565           0.0201            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       566           0.0201            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       567           0.0201            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       568           0.0200            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       569           0.0199            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       570           0.0198            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       571           0.0198            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       572           0.0197            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       573           0.0196            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       574           0.0196            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       575           0.0195            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       576           0.0195            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       577           0.0195            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       578           0.0194            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       579           0.0193            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       580           0.0192            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       581           0.0191            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       582           0.0190            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       583           0.0190            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       584           0.0189            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       585           0.0188            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       586           0.0188            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       587           0.0187            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       588           0.0187            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       589           0.0186            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       590           0.0185            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       591           0.0185            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       592           0.0185            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       593           0.0184            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       594           0.0184            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       595           0.0183            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       596           0.0183            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       597           0.0182            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       598           0.0182            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       599           0.0181            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       600           0.0181            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       601           0.0180            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       602           0.0179            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       603           0.0179            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       604           0.0178            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       605           0.0178            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       606           0.0177            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       607           0.0177            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       608           0.0176            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       609           0.0175            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       610           0.0175            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       611           0.0174            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       612           0.0174            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       613           0.0173            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       614           0.0172            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       615           0.0172            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       616           0.0171            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       617           0.0170            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       618           0.0170            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       619           0.0169            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       620           0.0168            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       621           0.0168            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       622           0.0168            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       623           0.0167            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       624           0.0166            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       625           0.0165            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       626           0.0165            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       627           0.0164            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       628           0.0163            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       629           0.0163            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       630           0.0162            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       631           0.0162            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       632           0.0162            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       633           0.0161            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       634           0.0161            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       635           0.0161            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       636           0.0160            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       637           0.0159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       638           0.0159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       639           0.0159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       640           0.0159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       641           0.0158            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       642           0.0158            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       643           0.0157            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       644           0.0157            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       645           0.0156            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       646           0.0155            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       647           0.0155            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       648           0.0155            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       649           0.0154            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       650           0.0154            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       651           0.0153            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       652           0.0153            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       653           0.0153            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       654           0.0152            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       655           0.0152            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       656           0.0151            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       657           0.0150            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       658           0.0150            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       659           0.0149            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       660           0.0149            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       661           0.0149            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       662           0.0148            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       663           0.0147            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       664           0.0147            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       665           0.0146            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       666           0.0146            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       667           0.0146            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       668           0.0145            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       669           0.0145            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       670           0.0144            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       671           0.0144            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       672           0.0144            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       673           0.0143            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       674           0.0143            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       675           0.0142            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       676           0.0142            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       677           0.0141            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       678           0.0141            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       679           0.0140            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       680           0.0140            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       681           0.0139            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       682           0.0139            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       683           0.0139            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       684           0.0138            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       685           0.0138            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       686           0.0138            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       687           0.0137            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       688           0.0137            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       689           0.0137            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       690           0.0136            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       691           0.0136            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       692           0.0136            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       693           0.0135            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       694           0.0135            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       695           0.0134            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       696           0.0133            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       697           0.0133            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       698           0.0133            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       699           0.0132            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       700           0.0132            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       701           0.0131            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       702           0.0131            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       703           0.0130            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       704           0.0130            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       705           0.0129            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       706           0.0129            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       707           0.0129            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       708           0.0128            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       709           0.0128            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       710           0.0128            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       711           0.0127            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       712           0.0127            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       713           0.0127            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       714           0.0126            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       715           0.0125            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       716           0.0125            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       717           0.0124            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       718           0.0124            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       719           0.0124            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       720           0.0123            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       721           0.0123            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       722           0.0123            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       723           0.0122            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       724           0.0122            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       725           0.0122            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       726           0.0121            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       727           0.0121            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       728           0.0120            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       729           0.0120            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       730           0.0120            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       731           0.0119            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       732           0.0119            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       733           0.0118            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       734           0.0118            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       735           0.0118            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       736           0.0117            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       737           0.0117            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       738           0.0117            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       739           0.0116            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       740           0.0116            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       741           0.0115            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       742           0.0115            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       743           0.0114            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       744           0.0114            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       745           0.0113            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       746           0.0113            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       747           0.0113            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       748           0.0112            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       749           0.0112            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       750           0.0112            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       751           0.0111            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       752           0.0111            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       753           0.0110            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       754           0.0110            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       755           0.0109            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       756           0.0109            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       757           0.0108            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       758           0.0108            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       759           0.0108            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       760           0.0108            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       761           0.0107            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       762           0.0107            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       763           0.0106            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       764           0.0106            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       765           0.0106            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       766           0.0105            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       767           0.0105            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       768           0.0105            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       769           0.0105            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       770           0.0104            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       771           0.0104            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       772           0.0103            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       773           0.0103            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       774           0.0103            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       775           0.0102            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       776           0.0102            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       777           0.0102            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       778           0.0101            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       779           0.0101            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       780           0.0100            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       781           0.0100            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       782           0.0100            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       783           0.0099            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       784           0.0099            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       785           0.0099            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       786           0.0099            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       787           0.0098            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       788           0.0098            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       789           0.0098            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       790           0.0098            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       791           0.0098            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       792           0.0098            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       793           0.0097            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       794           0.0097            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       795           0.0097            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       796           0.0097            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       797           0.0096            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       798           0.0096            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       799           0.0096            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       800           0.0095            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       801           0.0095            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       802           0.0095            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       803           0.0095            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       804           0.0094            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       805           0.0094            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       806           0.0093            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       807           0.0093            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       808           0.0093            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       809           0.0093            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       810           0.0092            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       811           0.0092            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       812           0.0092            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       813           0.0091            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       814           0.0091            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       815           0.0091            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       816           0.0091            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       817           0.0090            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       818           0.0090            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       819           0.0090            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       820           0.0090            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       821           0.0089            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       822           0.0089            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       823           0.0089            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       824           0.0089            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       825           0.0088            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       826           0.0088            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       827           0.0088            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       828           0.0087            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       829           0.0087            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       830           0.0086            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       831           0.0086            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       832           0.0086            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       833           0.0085            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       834           0.0085            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       835           0.0084            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       836           0.0084            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       837           0.0084            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       838           0.0083            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       839           0.0083            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       840           0.0083            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       841           0.0083            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       842           0.0082            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       843           0.0082            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       844           0.0082            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       845           0.0082            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       846           0.0082            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       847           0.0081            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       848           0.0081            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       849           0.0081            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       850           0.0080            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       851           0.0080            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       852           0.0080            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       853           0.0080            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       854           0.0079            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       855           0.0079            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       856           0.0079            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       857           0.0079            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       858           0.0078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       859           0.0078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       860           0.0078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       861           0.0078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       862           0.0077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       863           0.0077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       864           0.0077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       865           0.0077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       866           0.0077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       867           0.0076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       868           0.0076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       869           0.0076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       870           0.0076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       871           0.0075            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       872           0.0075            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       873           0.0075            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       874           0.0075            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       875           0.0075            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       876           0.0074            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       877           0.0074            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       878           0.0074            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       879           0.0074            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       880           0.0073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       881           0.0073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       882           0.0073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       883           0.0073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       884           0.0073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       885           0.0072            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       886           0.0072            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       887           0.0072            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       888           0.0072            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       889           0.0072            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       890           0.0071            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       891           0.0071            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       892           0.0071            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       893           0.0071            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       894           0.0070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       895           0.0070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       896           0.0070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       897           0.0070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       898           0.0070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       899           0.0069            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       900           0.0069            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       901           0.0069            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       902           0.0069            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       903           0.0068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       904           0.0068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       905           0.0068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       906           0.0068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       907           0.0068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       908           0.0067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       909           0.0067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       910           0.0067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       911           0.0067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       912           0.0067            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       913           0.0066            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       914           0.0066            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       915           0.0066            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       916           0.0066            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       917           0.0066            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       918           0.0065            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       919           0.0065            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       920           0.0065            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       921           0.0065            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       922           0.0065            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       923           0.0064            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       924           0.0064            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       925           0.0064            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       926           0.0064            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       927           0.0063            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       928           0.0063            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       929           0.0063            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       930           0.0063            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       931           0.0063            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       932           0.0062            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       933           0.0062            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       934           0.0062            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       935           0.0062            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       936           0.0062            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       937           0.0061            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       938           0.0061            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       939           0.0061            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       940           0.0061            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       941           0.0061            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       942           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       943           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       944           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       945           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       946           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       947           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       948           0.0060            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       949           0.0059            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       950           0.0059            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       951           0.0059            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       952           0.0058            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       953           0.0058            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       954           0.0058            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       955           0.0058            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       956           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       957           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       958           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       959           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       960           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       961           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       962           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       963           0.0057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       964           0.0056            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       965           0.0056            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       966           0.0056            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       967           0.0056            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       968           0.0056            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       969           0.0056            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       970           0.0055            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       971           0.0055            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       972           0.0055            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       973           0.0055            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       974           0.0055            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       975           0.0054            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       976           0.0054            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       977           0.0054            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       978           0.0054            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       979           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       980           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       981           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       982           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       983           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       984           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       985           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       986           0.0053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       987           0.0052            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       988           0.0052            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       989           0.0052            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       990           0.0052            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       991           0.0052            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       992           0.0051            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       993           0.0051            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       994           0.0051            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       995           0.0051            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       996           0.0051            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       997           0.0050            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       998           0.0050            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "       999           0.0050            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "      1000           0.0050            0.00s\n"
     ]
    }
   ],
   "source": [
    "skl_losses_2 = []\n",
    "skl_clf_2 = GradientBoostingClassifier(learning_rate=.1, n_estimators=1, random_state=np.random.mtrand.RandomState(17), \\\n",
    "                                     init=ZeroEstimator(), verbose=1, warm_start=True)\n",
    "\n",
    "for i in range(1000):\n",
    "    skl_clf_2.fit(X_train, Y_train)\n",
    "    skl_clf_2.n_estimators += 1\n",
    "    skl_losses_2.append(L_log(Y_test, skl_clf_2.decision_function(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Бэггинг по 5 деревьев **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t, Train loss: 1.1541 \t, Test loss: 1.1904 \t\n",
      "Iteration: 1 \t, Train loss: 1.0486 \t, Test loss: 1.0927 \t\n",
      "Iteration: 2 \t, Train loss: 0.9656 \t, Test loss: 1.0423 \t\n",
      "Iteration: 3 \t, Train loss: 0.8931 \t, Test loss: 1.0131 \t\n",
      "Iteration: 4 \t, Train loss: 0.8337 \t, Test loss: 0.9658 \t\n",
      "Iteration: 5 \t, Train loss: 0.7831 \t, Test loss: 0.9163 \t\n",
      "Iteration: 6 \t, Train loss: 0.7382 \t, Test loss: 0.8788 \t\n",
      "Iteration: 7 \t, Train loss: 0.6988 \t, Test loss: 0.8397 \t\n",
      "Iteration: 8 \t, Train loss: 0.6632 \t, Test loss: 0.8100 \t\n",
      "Iteration: 9 \t, Train loss: 0.6293 \t, Test loss: 0.7688 \t\n",
      "Iteration: 10 \t, Train loss: 0.6008 \t, Test loss: 0.7443 \t\n",
      "Iteration: 11 \t, Train loss: 0.5750 \t, Test loss: 0.7161 \t\n",
      "Iteration: 12 \t, Train loss: 0.5507 \t, Test loss: 0.6915 \t\n",
      "Iteration: 13 \t, Train loss: 0.5288 \t, Test loss: 0.6670 \t\n",
      "Iteration: 14 \t, Train loss: 0.5097 \t, Test loss: 0.6469 \t\n",
      "Iteration: 15 \t, Train loss: 0.4911 \t, Test loss: 0.6282 \t\n",
      "Iteration: 16 \t, Train loss: 0.4736 \t, Test loss: 0.6138 \t\n",
      "Iteration: 17 \t, Train loss: 0.4576 \t, Test loss: 0.5944 \t\n",
      "Iteration: 18 \t, Train loss: 0.4427 \t, Test loss: 0.5850 \t\n",
      "Iteration: 19 \t, Train loss: 0.4283 \t, Test loss: 0.5708 \t\n",
      "Iteration: 20 \t, Train loss: 0.4152 \t, Test loss: 0.5539 \t\n",
      "Iteration: 21 \t, Train loss: 0.4031 \t, Test loss: 0.5418 \t\n",
      "Iteration: 22 \t, Train loss: 0.3915 \t, Test loss: 0.5301 \t\n",
      "Iteration: 23 \t, Train loss: 0.3808 \t, Test loss: 0.5169 \t\n",
      "Iteration: 24 \t, Train loss: 0.3700 \t, Test loss: 0.5048 \t\n",
      "Iteration: 25 \t, Train loss: 0.3603 \t, Test loss: 0.4968 \t\n",
      "Iteration: 26 \t, Train loss: 0.3517 \t, Test loss: 0.4879 \t\n",
      "Iteration: 27 \t, Train loss: 0.3427 \t, Test loss: 0.4818 \t\n",
      "Iteration: 28 \t, Train loss: 0.3348 \t, Test loss: 0.4735 \t\n",
      "Iteration: 29 \t, Train loss: 0.3277 \t, Test loss: 0.4685 \t\n",
      "Iteration: 30 \t, Train loss: 0.3204 \t, Test loss: 0.4612 \t\n",
      "Iteration: 31 \t, Train loss: 0.3137 \t, Test loss: 0.4535 \t\n",
      "Iteration: 32 \t, Train loss: 0.3072 \t, Test loss: 0.4457 \t\n",
      "Iteration: 33 \t, Train loss: 0.3012 \t, Test loss: 0.4380 \t\n",
      "Iteration: 34 \t, Train loss: 0.2958 \t, Test loss: 0.4343 \t\n",
      "Iteration: 35 \t, Train loss: 0.2901 \t, Test loss: 0.4305 \t\n",
      "Iteration: 36 \t, Train loss: 0.2851 \t, Test loss: 0.4265 \t\n",
      "Iteration: 37 \t, Train loss: 0.2804 \t, Test loss: 0.4217 \t\n",
      "Iteration: 38 \t, Train loss: 0.2753 \t, Test loss: 0.4169 \t\n",
      "Iteration: 39 \t, Train loss: 0.2706 \t, Test loss: 0.4124 \t\n",
      "Iteration: 40 \t, Train loss: 0.2661 \t, Test loss: 0.4097 \t\n",
      "Iteration: 41 \t, Train loss: 0.2618 \t, Test loss: 0.4057 \t\n",
      "Iteration: 42 \t, Train loss: 0.2576 \t, Test loss: 0.4024 \t\n",
      "Iteration: 43 \t, Train loss: 0.2539 \t, Test loss: 0.4008 \t\n",
      "Iteration: 44 \t, Train loss: 0.2504 \t, Test loss: 0.3971 \t\n",
      "Iteration: 45 \t, Train loss: 0.2470 \t, Test loss: 0.3936 \t\n",
      "Iteration: 46 \t, Train loss: 0.2428 \t, Test loss: 0.3901 \t\n",
      "Iteration: 47 \t, Train loss: 0.2397 \t, Test loss: 0.3873 \t\n",
      "Iteration: 48 \t, Train loss: 0.2365 \t, Test loss: 0.3853 \t\n",
      "Iteration: 49 \t, Train loss: 0.2336 \t, Test loss: 0.3831 \t\n",
      "Iteration: 50 \t, Train loss: 0.2308 \t, Test loss: 0.3807 \t\n",
      "Iteration: 51 \t, Train loss: 0.2277 \t, Test loss: 0.3776 \t\n",
      "Iteration: 52 \t, Train loss: 0.2249 \t, Test loss: 0.3742 \t\n",
      "Iteration: 53 \t, Train loss: 0.2224 \t, Test loss: 0.3718 \t\n",
      "Iteration: 54 \t, Train loss: 0.2199 \t, Test loss: 0.3704 \t\n",
      "Iteration: 55 \t, Train loss: 0.2175 \t, Test loss: 0.3685 \t\n",
      "Iteration: 56 \t, Train loss: 0.2156 \t, Test loss: 0.3680 \t\n",
      "Iteration: 57 \t, Train loss: 0.2133 \t, Test loss: 0.3653 \t\n",
      "Iteration: 58 \t, Train loss: 0.2114 \t, Test loss: 0.3636 \t\n",
      "Iteration: 59 \t, Train loss: 0.2092 \t, Test loss: 0.3617 \t\n",
      "Iteration: 60 \t, Train loss: 0.2070 \t, Test loss: 0.3595 \t\n",
      "Iteration: 61 \t, Train loss: 0.2051 \t, Test loss: 0.3572 \t\n",
      "Iteration: 62 \t, Train loss: 0.2034 \t, Test loss: 0.3556 \t\n",
      "Iteration: 63 \t, Train loss: 0.2017 \t, Test loss: 0.3538 \t\n",
      "Iteration: 64 \t, Train loss: 0.2001 \t, Test loss: 0.3523 \t\n",
      "Iteration: 65 \t, Train loss: 0.1983 \t, Test loss: 0.3507 \t\n",
      "Iteration: 66 \t, Train loss: 0.1967 \t, Test loss: 0.3489 \t\n",
      "Iteration: 67 \t, Train loss: 0.1953 \t, Test loss: 0.3478 \t\n",
      "Iteration: 68 \t, Train loss: 0.1938 \t, Test loss: 0.3460 \t\n",
      "Iteration: 69 \t, Train loss: 0.1923 \t, Test loss: 0.3452 \t\n",
      "Iteration: 70 \t, Train loss: 0.1908 \t, Test loss: 0.3449 \t\n",
      "Iteration: 71 \t, Train loss: 0.1895 \t, Test loss: 0.3436 \t\n",
      "Iteration: 72 \t, Train loss: 0.1882 \t, Test loss: 0.3422 \t\n",
      "Iteration: 73 \t, Train loss: 0.1869 \t, Test loss: 0.3415 \t\n",
      "Iteration: 74 \t, Train loss: 0.1853 \t, Test loss: 0.3404 \t\n",
      "Iteration: 75 \t, Train loss: 0.1843 \t, Test loss: 0.3398 \t\n",
      "Iteration: 76 \t, Train loss: 0.1832 \t, Test loss: 0.3386 \t\n",
      "Iteration: 77 \t, Train loss: 0.1822 \t, Test loss: 0.3383 \t\n",
      "Iteration: 78 \t, Train loss: 0.1809 \t, Test loss: 0.3368 \t\n",
      "Iteration: 79 \t, Train loss: 0.1797 \t, Test loss: 0.3358 \t\n",
      "Iteration: 80 \t, Train loss: 0.1787 \t, Test loss: 0.3346 \t\n",
      "Iteration: 81 \t, Train loss: 0.1777 \t, Test loss: 0.3343 \t\n",
      "Iteration: 82 \t, Train loss: 0.1767 \t, Test loss: 0.3339 \t\n",
      "Iteration: 83 \t, Train loss: 0.1756 \t, Test loss: 0.3326 \t\n",
      "Iteration: 84 \t, Train loss: 0.1746 \t, Test loss: 0.3313 \t\n",
      "Iteration: 85 \t, Train loss: 0.1736 \t, Test loss: 0.3297 \t\n",
      "Iteration: 86 \t, Train loss: 0.1724 \t, Test loss: 0.3283 \t\n",
      "Iteration: 87 \t, Train loss: 0.1715 \t, Test loss: 0.3264 \t\n",
      "Iteration: 88 \t, Train loss: 0.1706 \t, Test loss: 0.3258 \t\n",
      "Iteration: 89 \t, Train loss: 0.1699 \t, Test loss: 0.3252 \t\n",
      "Iteration: 90 \t, Train loss: 0.1688 \t, Test loss: 0.3241 \t\n",
      "Iteration: 91 \t, Train loss: 0.1678 \t, Test loss: 0.3234 \t\n",
      "Iteration: 92 \t, Train loss: 0.1670 \t, Test loss: 0.3225 \t\n",
      "Iteration: 93 \t, Train loss: 0.1662 \t, Test loss: 0.3222 \t\n",
      "Iteration: 94 \t, Train loss: 0.1654 \t, Test loss: 0.3218 \t\n",
      "Iteration: 95 \t, Train loss: 0.1646 \t, Test loss: 0.3208 \t\n",
      "Iteration: 96 \t, Train loss: 0.1639 \t, Test loss: 0.3201 \t\n",
      "Iteration: 97 \t, Train loss: 0.1629 \t, Test loss: 0.3194 \t\n",
      "Iteration: 98 \t, Train loss: 0.1620 \t, Test loss: 0.3180 \t\n",
      "Iteration: 99 \t, Train loss: 0.1613 \t, Test loss: 0.3179 \t\n",
      "Iteration: 100 \t, Train loss: 0.1605 \t, Test loss: 0.3170 \t\n",
      "Iteration: 101 \t, Train loss: 0.1598 \t, Test loss: 0.3164 \t\n",
      "Iteration: 102 \t, Train loss: 0.1591 \t, Test loss: 0.3160 \t\n",
      "Iteration: 103 \t, Train loss: 0.1583 \t, Test loss: 0.3158 \t\n",
      "Iteration: 104 \t, Train loss: 0.1574 \t, Test loss: 0.3153 \t\n",
      "Iteration: 105 \t, Train loss: 0.1567 \t, Test loss: 0.3148 \t\n",
      "Iteration: 106 \t, Train loss: 0.1559 \t, Test loss: 0.3132 \t\n",
      "Iteration: 107 \t, Train loss: 0.1551 \t, Test loss: 0.3125 \t\n",
      "Iteration: 108 \t, Train loss: 0.1544 \t, Test loss: 0.3116 \t\n",
      "Iteration: 109 \t, Train loss: 0.1539 \t, Test loss: 0.3111 \t\n",
      "Iteration: 110 \t, Train loss: 0.1533 \t, Test loss: 0.3108 \t\n",
      "Iteration: 111 \t, Train loss: 0.1528 \t, Test loss: 0.3100 \t\n",
      "Iteration: 112 \t, Train loss: 0.1521 \t, Test loss: 0.3094 \t\n",
      "Iteration: 113 \t, Train loss: 0.1516 \t, Test loss: 0.3089 \t\n",
      "Iteration: 114 \t, Train loss: 0.1510 \t, Test loss: 0.3088 \t\n",
      "Iteration: 115 \t, Train loss: 0.1504 \t, Test loss: 0.3081 \t\n",
      "Iteration: 116 \t, Train loss: 0.1497 \t, Test loss: 0.3077 \t\n",
      "Iteration: 117 \t, Train loss: 0.1490 \t, Test loss: 0.3069 \t\n",
      "Iteration: 118 \t, Train loss: 0.1484 \t, Test loss: 0.3066 \t\n",
      "Iteration: 119 \t, Train loss: 0.1480 \t, Test loss: 0.3056 \t\n",
      "Iteration: 120 \t, Train loss: 0.1474 \t, Test loss: 0.3056 \t\n",
      "Iteration: 121 \t, Train loss: 0.1469 \t, Test loss: 0.3047 \t\n",
      "Iteration: 122 \t, Train loss: 0.1464 \t, Test loss: 0.3047 \t\n",
      "Iteration: 123 \t, Train loss: 0.1456 \t, Test loss: 0.3039 \t\n",
      "Iteration: 124 \t, Train loss: 0.1451 \t, Test loss: 0.3034 \t\n",
      "Iteration: 125 \t, Train loss: 0.1444 \t, Test loss: 0.3024 \t\n",
      "Iteration: 126 \t, Train loss: 0.1439 \t, Test loss: 0.3021 \t\n",
      "Iteration: 127 \t, Train loss: 0.1433 \t, Test loss: 0.3020 \t\n",
      "Iteration: 128 \t, Train loss: 0.1427 \t, Test loss: 0.3016 \t\n",
      "Iteration: 129 \t, Train loss: 0.1422 \t, Test loss: 0.3011 \t\n",
      "Iteration: 130 \t, Train loss: 0.1417 \t, Test loss: 0.3007 \t\n",
      "Iteration: 131 \t, Train loss: 0.1412 \t, Test loss: 0.3001 \t\n",
      "Iteration: 132 \t, Train loss: 0.1406 \t, Test loss: 0.2999 \t\n",
      "Iteration: 133 \t, Train loss: 0.1401 \t, Test loss: 0.2994 \t\n",
      "Iteration: 134 \t, Train loss: 0.1396 \t, Test loss: 0.2992 \t\n",
      "Iteration: 135 \t, Train loss: 0.1390 \t, Test loss: 0.2988 \t\n",
      "Iteration: 136 \t, Train loss: 0.1385 \t, Test loss: 0.2985 \t\n",
      "Iteration: 137 \t, Train loss: 0.1380 \t, Test loss: 0.2976 \t\n",
      "Iteration: 138 \t, Train loss: 0.1375 \t, Test loss: 0.2966 \t\n",
      "Iteration: 139 \t, Train loss: 0.1370 \t, Test loss: 0.2959 \t\n",
      "Iteration: 140 \t, Train loss: 0.1363 \t, Test loss: 0.2955 \t\n",
      "Iteration: 141 \t, Train loss: 0.1359 \t, Test loss: 0.2947 \t\n",
      "Iteration: 142 \t, Train loss: 0.1354 \t, Test loss: 0.2943 \t\n",
      "Iteration: 143 \t, Train loss: 0.1348 \t, Test loss: 0.2941 \t\n",
      "Iteration: 144 \t, Train loss: 0.1343 \t, Test loss: 0.2940 \t\n",
      "Iteration: 145 \t, Train loss: 0.1338 \t, Test loss: 0.2935 \t\n",
      "Iteration: 146 \t, Train loss: 0.1332 \t, Test loss: 0.2926 \t\n",
      "Iteration: 147 \t, Train loss: 0.1328 \t, Test loss: 0.2920 \t\n",
      "Iteration: 148 \t, Train loss: 0.1324 \t, Test loss: 0.2916 \t\n",
      "Iteration: 149 \t, Train loss: 0.1319 \t, Test loss: 0.2914 \t\n",
      "Iteration: 150 \t, Train loss: 0.1314 \t, Test loss: 0.2908 \t\n",
      "Iteration: 151 \t, Train loss: 0.1309 \t, Test loss: 0.2907 \t\n",
      "Iteration: 152 \t, Train loss: 0.1305 \t, Test loss: 0.2907 \t\n",
      "Iteration: 153 \t, Train loss: 0.1301 \t, Test loss: 0.2901 \t\n",
      "Iteration: 154 \t, Train loss: 0.1296 \t, Test loss: 0.2898 \t\n",
      "Iteration: 155 \t, Train loss: 0.1292 \t, Test loss: 0.2892 \t\n",
      "Iteration: 156 \t, Train loss: 0.1287 \t, Test loss: 0.2890 \t\n",
      "Iteration: 157 \t, Train loss: 0.1283 \t, Test loss: 0.2885 \t\n",
      "Iteration: 158 \t, Train loss: 0.1278 \t, Test loss: 0.2880 \t\n",
      "Iteration: 159 \t, Train loss: 0.1274 \t, Test loss: 0.2876 \t\n",
      "Iteration: 160 \t, Train loss: 0.1270 \t, Test loss: 0.2872 \t\n",
      "Iteration: 161 \t, Train loss: 0.1265 \t, Test loss: 0.2868 \t\n",
      "Iteration: 162 \t, Train loss: 0.1261 \t, Test loss: 0.2868 \t\n",
      "Iteration: 163 \t, Train loss: 0.1256 \t, Test loss: 0.2864 \t\n",
      "Iteration: 164 \t, Train loss: 0.1253 \t, Test loss: 0.2862 \t\n",
      "Iteration: 165 \t, Train loss: 0.1249 \t, Test loss: 0.2860 \t\n",
      "Iteration: 166 \t, Train loss: 0.1245 \t, Test loss: 0.2860 \t\n",
      "Iteration: 167 \t, Train loss: 0.1240 \t, Test loss: 0.2860 \t\n",
      "Iteration: 168 \t, Train loss: 0.1236 \t, Test loss: 0.2857 \t\n",
      "Iteration: 169 \t, Train loss: 0.1232 \t, Test loss: 0.2855 \t\n",
      "Iteration: 170 \t, Train loss: 0.1226 \t, Test loss: 0.2849 \t\n",
      "Iteration: 171 \t, Train loss: 0.1223 \t, Test loss: 0.2845 \t\n",
      "Iteration: 172 \t, Train loss: 0.1217 \t, Test loss: 0.2839 \t\n",
      "Iteration: 173 \t, Train loss: 0.1214 \t, Test loss: 0.2838 \t\n",
      "Iteration: 174 \t, Train loss: 0.1210 \t, Test loss: 0.2838 \t\n",
      "Iteration: 175 \t, Train loss: 0.1206 \t, Test loss: 0.2835 \t\n",
      "Iteration: 176 \t, Train loss: 0.1203 \t, Test loss: 0.2831 \t\n",
      "Iteration: 177 \t, Train loss: 0.1199 \t, Test loss: 0.2828 \t\n",
      "Iteration: 178 \t, Train loss: 0.1194 \t, Test loss: 0.2825 \t\n",
      "Iteration: 179 \t, Train loss: 0.1190 \t, Test loss: 0.2820 \t\n",
      "Iteration: 180 \t, Train loss: 0.1186 \t, Test loss: 0.2816 \t\n",
      "Iteration: 181 \t, Train loss: 0.1182 \t, Test loss: 0.2809 \t\n",
      "Iteration: 182 \t, Train loss: 0.1178 \t, Test loss: 0.2809 \t\n",
      "Iteration: 183 \t, Train loss: 0.1175 \t, Test loss: 0.2806 \t\n",
      "Iteration: 184 \t, Train loss: 0.1171 \t, Test loss: 0.2799 \t\n",
      "Iteration: 185 \t, Train loss: 0.1168 \t, Test loss: 0.2795 \t\n",
      "Iteration: 186 \t, Train loss: 0.1164 \t, Test loss: 0.2788 \t\n",
      "Iteration: 187 \t, Train loss: 0.1161 \t, Test loss: 0.2787 \t\n",
      "Iteration: 188 \t, Train loss: 0.1158 \t, Test loss: 0.2783 \t\n",
      "Iteration: 189 \t, Train loss: 0.1153 \t, Test loss: 0.2781 \t\n",
      "Iteration: 190 \t, Train loss: 0.1149 \t, Test loss: 0.2776 \t\n",
      "Iteration: 191 \t, Train loss: 0.1146 \t, Test loss: 0.2773 \t\n",
      "Iteration: 192 \t, Train loss: 0.1143 \t, Test loss: 0.2771 \t\n",
      "Iteration: 193 \t, Train loss: 0.1139 \t, Test loss: 0.2770 \t\n",
      "Iteration: 194 \t, Train loss: 0.1135 \t, Test loss: 0.2764 \t\n",
      "Iteration: 195 \t, Train loss: 0.1132 \t, Test loss: 0.2762 \t\n",
      "Iteration: 196 \t, Train loss: 0.1128 \t, Test loss: 0.2760 \t\n",
      "Iteration: 197 \t, Train loss: 0.1126 \t, Test loss: 0.2761 \t\n",
      "Iteration: 198 \t, Train loss: 0.1123 \t, Test loss: 0.2758 \t\n",
      "Iteration: 199 \t, Train loss: 0.1118 \t, Test loss: 0.2752 \t\n",
      "Iteration: 200 \t, Train loss: 0.1114 \t, Test loss: 0.2747 \t\n",
      "Iteration: 201 \t, Train loss: 0.1110 \t, Test loss: 0.2747 \t\n",
      "Iteration: 202 \t, Train loss: 0.1107 \t, Test loss: 0.2743 \t\n",
      "Iteration: 203 \t, Train loss: 0.1105 \t, Test loss: 0.2740 \t\n",
      "Iteration: 204 \t, Train loss: 0.1100 \t, Test loss: 0.2736 \t\n",
      "Iteration: 205 \t, Train loss: 0.1096 \t, Test loss: 0.2733 \t\n",
      "Iteration: 206 \t, Train loss: 0.1093 \t, Test loss: 0.2730 \t\n",
      "Iteration: 207 \t, Train loss: 0.1090 \t, Test loss: 0.2727 \t\n",
      "Iteration: 208 \t, Train loss: 0.1086 \t, Test loss: 0.2725 \t\n",
      "Iteration: 209 \t, Train loss: 0.1082 \t, Test loss: 0.2722 \t\n",
      "Iteration: 210 \t, Train loss: 0.1078 \t, Test loss: 0.2716 \t\n",
      "Iteration: 211 \t, Train loss: 0.1075 \t, Test loss: 0.2716 \t\n",
      "Iteration: 212 \t, Train loss: 0.1072 \t, Test loss: 0.2712 \t\n",
      "Iteration: 213 \t, Train loss: 0.1069 \t, Test loss: 0.2710 \t\n",
      "Iteration: 214 \t, Train loss: 0.1064 \t, Test loss: 0.2707 \t\n",
      "Iteration: 215 \t, Train loss: 0.1061 \t, Test loss: 0.2705 \t\n",
      "Iteration: 216 \t, Train loss: 0.1058 \t, Test loss: 0.2702 \t\n",
      "Iteration: 217 \t, Train loss: 0.1055 \t, Test loss: 0.2704 \t\n",
      "Iteration: 218 \t, Train loss: 0.1052 \t, Test loss: 0.2700 \t\n",
      "Iteration: 219 \t, Train loss: 0.1049 \t, Test loss: 0.2696 \t\n",
      "Iteration: 220 \t, Train loss: 0.1046 \t, Test loss: 0.2696 \t\n",
      "Iteration: 221 \t, Train loss: 0.1043 \t, Test loss: 0.2693 \t\n",
      "Iteration: 222 \t, Train loss: 0.1040 \t, Test loss: 0.2691 \t\n",
      "Iteration: 223 \t, Train loss: 0.1036 \t, Test loss: 0.2690 \t\n",
      "Iteration: 224 \t, Train loss: 0.1034 \t, Test loss: 0.2688 \t\n",
      "Iteration: 225 \t, Train loss: 0.1031 \t, Test loss: 0.2683 \t\n",
      "Iteration: 226 \t, Train loss: 0.1028 \t, Test loss: 0.2681 \t\n",
      "Iteration: 227 \t, Train loss: 0.1025 \t, Test loss: 0.2679 \t\n",
      "Iteration: 228 \t, Train loss: 0.1023 \t, Test loss: 0.2676 \t\n",
      "Iteration: 229 \t, Train loss: 0.1020 \t, Test loss: 0.2676 \t\n",
      "Iteration: 230 \t, Train loss: 0.1017 \t, Test loss: 0.2675 \t\n",
      "Iteration: 231 \t, Train loss: 0.1015 \t, Test loss: 0.2673 \t\n",
      "Iteration: 232 \t, Train loss: 0.1012 \t, Test loss: 0.2670 \t\n",
      "Iteration: 233 \t, Train loss: 0.1009 \t, Test loss: 0.2667 \t\n",
      "Iteration: 234 \t, Train loss: 0.1006 \t, Test loss: 0.2666 \t\n",
      "Iteration: 235 \t, Train loss: 0.1003 \t, Test loss: 0.2663 \t\n",
      "Iteration: 236 \t, Train loss: 0.1000 \t, Test loss: 0.2662 \t\n",
      "Iteration: 237 \t, Train loss: 0.0998 \t, Test loss: 0.2658 \t\n",
      "Iteration: 238 \t, Train loss: 0.0995 \t, Test loss: 0.2660 \t\n",
      "Iteration: 239 \t, Train loss: 0.0992 \t, Test loss: 0.2658 \t\n",
      "Iteration: 240 \t, Train loss: 0.0989 \t, Test loss: 0.2657 \t\n",
      "Iteration: 241 \t, Train loss: 0.0986 \t, Test loss: 0.2656 \t\n",
      "Iteration: 242 \t, Train loss: 0.0984 \t, Test loss: 0.2653 \t\n",
      "Iteration: 243 \t, Train loss: 0.0982 \t, Test loss: 0.2654 \t\n",
      "Iteration: 244 \t, Train loss: 0.0979 \t, Test loss: 0.2652 \t\n",
      "Iteration: 245 \t, Train loss: 0.0976 \t, Test loss: 0.2648 \t\n",
      "Iteration: 246 \t, Train loss: 0.0973 \t, Test loss: 0.2647 \t\n",
      "Iteration: 247 \t, Train loss: 0.0969 \t, Test loss: 0.2645 \t\n",
      "Iteration: 248 \t, Train loss: 0.0966 \t, Test loss: 0.2642 \t\n",
      "Iteration: 249 \t, Train loss: 0.0962 \t, Test loss: 0.2640 \t\n",
      "Iteration: 250 \t, Train loss: 0.0959 \t, Test loss: 0.2640 \t\n",
      "Iteration: 251 \t, Train loss: 0.0957 \t, Test loss: 0.2637 \t\n",
      "Iteration: 252 \t, Train loss: 0.0954 \t, Test loss: 0.2637 \t\n",
      "Iteration: 253 \t, Train loss: 0.0952 \t, Test loss: 0.2635 \t\n",
      "Iteration: 254 \t, Train loss: 0.0949 \t, Test loss: 0.2631 \t\n",
      "Iteration: 255 \t, Train loss: 0.0946 \t, Test loss: 0.2628 \t\n",
      "Iteration: 256 \t, Train loss: 0.0943 \t, Test loss: 0.2626 \t\n",
      "Iteration: 257 \t, Train loss: 0.0940 \t, Test loss: 0.2624 \t\n",
      "Iteration: 258 \t, Train loss: 0.0938 \t, Test loss: 0.2622 \t\n",
      "Iteration: 259 \t, Train loss: 0.0935 \t, Test loss: 0.2620 \t\n",
      "Iteration: 260 \t, Train loss: 0.0933 \t, Test loss: 0.2618 \t\n",
      "Iteration: 261 \t, Train loss: 0.0930 \t, Test loss: 0.2615 \t\n",
      "Iteration: 262 \t, Train loss: 0.0928 \t, Test loss: 0.2614 \t\n",
      "Iteration: 263 \t, Train loss: 0.0925 \t, Test loss: 0.2609 \t\n",
      "Iteration: 264 \t, Train loss: 0.0922 \t, Test loss: 0.2606 \t\n",
      "Iteration: 265 \t, Train loss: 0.0919 \t, Test loss: 0.2604 \t\n",
      "Iteration: 266 \t, Train loss: 0.0917 \t, Test loss: 0.2603 \t\n",
      "Iteration: 267 \t, Train loss: 0.0914 \t, Test loss: 0.2601 \t\n",
      "Iteration: 268 \t, Train loss: 0.0912 \t, Test loss: 0.2597 \t\n",
      "Iteration: 269 \t, Train loss: 0.0909 \t, Test loss: 0.2596 \t\n",
      "Iteration: 270 \t, Train loss: 0.0906 \t, Test loss: 0.2595 \t\n",
      "Iteration: 271 \t, Train loss: 0.0904 \t, Test loss: 0.2593 \t\n",
      "Iteration: 272 \t, Train loss: 0.0901 \t, Test loss: 0.2592 \t\n",
      "Iteration: 273 \t, Train loss: 0.0898 \t, Test loss: 0.2592 \t\n",
      "Iteration: 274 \t, Train loss: 0.0896 \t, Test loss: 0.2590 \t\n",
      "Iteration: 275 \t, Train loss: 0.0893 \t, Test loss: 0.2589 \t\n",
      "Iteration: 276 \t, Train loss: 0.0891 \t, Test loss: 0.2588 \t\n",
      "Iteration: 277 \t, Train loss: 0.0888 \t, Test loss: 0.2586 \t\n",
      "Iteration: 278 \t, Train loss: 0.0886 \t, Test loss: 0.2584 \t\n",
      "Iteration: 279 \t, Train loss: 0.0883 \t, Test loss: 0.2578 \t\n",
      "Iteration: 280 \t, Train loss: 0.0880 \t, Test loss: 0.2580 \t\n",
      "Iteration: 281 \t, Train loss: 0.0877 \t, Test loss: 0.2578 \t\n",
      "Iteration: 282 \t, Train loss: 0.0875 \t, Test loss: 0.2577 \t\n",
      "Iteration: 283 \t, Train loss: 0.0873 \t, Test loss: 0.2576 \t\n",
      "Iteration: 284 \t, Train loss: 0.0870 \t, Test loss: 0.2574 \t\n",
      "Iteration: 285 \t, Train loss: 0.0867 \t, Test loss: 0.2572 \t\n",
      "Iteration: 286 \t, Train loss: 0.0865 \t, Test loss: 0.2572 \t\n",
      "Iteration: 287 \t, Train loss: 0.0863 \t, Test loss: 0.2572 \t\n",
      "Iteration: 288 \t, Train loss: 0.0860 \t, Test loss: 0.2570 \t\n",
      "Iteration: 289 \t, Train loss: 0.0857 \t, Test loss: 0.2567 \t\n",
      "Iteration: 290 \t, Train loss: 0.0856 \t, Test loss: 0.2565 \t\n",
      "Iteration: 291 \t, Train loss: 0.0853 \t, Test loss: 0.2562 \t\n",
      "Iteration: 292 \t, Train loss: 0.0851 \t, Test loss: 0.2561 \t\n",
      "Iteration: 293 \t, Train loss: 0.0849 \t, Test loss: 0.2560 \t\n",
      "Iteration: 294 \t, Train loss: 0.0846 \t, Test loss: 0.2559 \t\n",
      "Iteration: 295 \t, Train loss: 0.0844 \t, Test loss: 0.2558 \t\n",
      "Iteration: 296 \t, Train loss: 0.0842 \t, Test loss: 0.2559 \t\n",
      "Iteration: 297 \t, Train loss: 0.0840 \t, Test loss: 0.2557 \t\n",
      "Iteration: 298 \t, Train loss: 0.0837 \t, Test loss: 0.2555 \t\n",
      "Iteration: 299 \t, Train loss: 0.0835 \t, Test loss: 0.2554 \t\n",
      "Iteration: 300 \t, Train loss: 0.0832 \t, Test loss: 0.2552 \t\n",
      "Iteration: 301 \t, Train loss: 0.0830 \t, Test loss: 0.2550 \t\n",
      "Iteration: 302 \t, Train loss: 0.0828 \t, Test loss: 0.2547 \t\n",
      "Iteration: 303 \t, Train loss: 0.0826 \t, Test loss: 0.2546 \t\n",
      "Iteration: 304 \t, Train loss: 0.0824 \t, Test loss: 0.2544 \t\n",
      "Iteration: 305 \t, Train loss: 0.0821 \t, Test loss: 0.2546 \t\n",
      "Iteration: 306 \t, Train loss: 0.0819 \t, Test loss: 0.2545 \t\n",
      "Iteration: 307 \t, Train loss: 0.0816 \t, Test loss: 0.2544 \t\n",
      "Iteration: 308 \t, Train loss: 0.0814 \t, Test loss: 0.2543 \t\n",
      "Iteration: 309 \t, Train loss: 0.0812 \t, Test loss: 0.2539 \t\n",
      "Iteration: 310 \t, Train loss: 0.0810 \t, Test loss: 0.2539 \t\n",
      "Iteration: 311 \t, Train loss: 0.0808 \t, Test loss: 0.2538 \t\n",
      "Iteration: 312 \t, Train loss: 0.0805 \t, Test loss: 0.2538 \t\n",
      "Iteration: 313 \t, Train loss: 0.0803 \t, Test loss: 0.2535 \t\n",
      "Iteration: 314 \t, Train loss: 0.0801 \t, Test loss: 0.2533 \t\n",
      "Iteration: 315 \t, Train loss: 0.0799 \t, Test loss: 0.2531 \t\n",
      "Iteration: 316 \t, Train loss: 0.0797 \t, Test loss: 0.2530 \t\n",
      "Iteration: 317 \t, Train loss: 0.0795 \t, Test loss: 0.2530 \t\n",
      "Iteration: 318 \t, Train loss: 0.0793 \t, Test loss: 0.2527 \t\n",
      "Iteration: 319 \t, Train loss: 0.0790 \t, Test loss: 0.2527 \t\n",
      "Iteration: 320 \t, Train loss: 0.0788 \t, Test loss: 0.2526 \t\n",
      "Iteration: 321 \t, Train loss: 0.0786 \t, Test loss: 0.2523 \t\n",
      "Iteration: 322 \t, Train loss: 0.0785 \t, Test loss: 0.2520 \t\n",
      "Iteration: 323 \t, Train loss: 0.0783 \t, Test loss: 0.2519 \t\n",
      "Iteration: 324 \t, Train loss: 0.0780 \t, Test loss: 0.2522 \t\n",
      "Iteration: 325 \t, Train loss: 0.0778 \t, Test loss: 0.2520 \t\n",
      "Iteration: 326 \t, Train loss: 0.0776 \t, Test loss: 0.2516 \t\n",
      "Iteration: 327 \t, Train loss: 0.0774 \t, Test loss: 0.2512 \t\n",
      "Iteration: 328 \t, Train loss: 0.0772 \t, Test loss: 0.2510 \t\n",
      "Iteration: 329 \t, Train loss: 0.0769 \t, Test loss: 0.2510 \t\n",
      "Iteration: 330 \t, Train loss: 0.0768 \t, Test loss: 0.2507 \t\n",
      "Iteration: 331 \t, Train loss: 0.0765 \t, Test loss: 0.2506 \t\n",
      "Iteration: 332 \t, Train loss: 0.0763 \t, Test loss: 0.2503 \t\n",
      "Iteration: 333 \t, Train loss: 0.0761 \t, Test loss: 0.2501 \t\n",
      "Iteration: 334 \t, Train loss: 0.0759 \t, Test loss: 0.2501 \t\n",
      "Iteration: 335 \t, Train loss: 0.0756 \t, Test loss: 0.2498 \t\n",
      "Iteration: 336 \t, Train loss: 0.0754 \t, Test loss: 0.2496 \t\n",
      "Iteration: 337 \t, Train loss: 0.0752 \t, Test loss: 0.2495 \t\n",
      "Iteration: 338 \t, Train loss: 0.0749 \t, Test loss: 0.2492 \t\n",
      "Iteration: 339 \t, Train loss: 0.0747 \t, Test loss: 0.2490 \t\n",
      "Iteration: 340 \t, Train loss: 0.0745 \t, Test loss: 0.2489 \t\n",
      "Iteration: 341 \t, Train loss: 0.0743 \t, Test loss: 0.2488 \t\n",
      "Iteration: 342 \t, Train loss: 0.0741 \t, Test loss: 0.2487 \t\n",
      "Iteration: 343 \t, Train loss: 0.0738 \t, Test loss: 0.2486 \t\n",
      "Iteration: 344 \t, Train loss: 0.0736 \t, Test loss: 0.2484 \t\n",
      "Iteration: 345 \t, Train loss: 0.0734 \t, Test loss: 0.2483 \t\n",
      "Iteration: 346 \t, Train loss: 0.0732 \t, Test loss: 0.2482 \t\n",
      "Iteration: 347 \t, Train loss: 0.0731 \t, Test loss: 0.2481 \t\n",
      "Iteration: 348 \t, Train loss: 0.0729 \t, Test loss: 0.2479 \t\n",
      "Iteration: 349 \t, Train loss: 0.0727 \t, Test loss: 0.2476 \t\n",
      "Iteration: 350 \t, Train loss: 0.0725 \t, Test loss: 0.2475 \t\n",
      "Iteration: 351 \t, Train loss: 0.0723 \t, Test loss: 0.2474 \t\n",
      "Iteration: 352 \t, Train loss: 0.0721 \t, Test loss: 0.2471 \t\n",
      "Iteration: 353 \t, Train loss: 0.0719 \t, Test loss: 0.2470 \t\n",
      "Iteration: 354 \t, Train loss: 0.0717 \t, Test loss: 0.2470 \t\n",
      "Iteration: 355 \t, Train loss: 0.0716 \t, Test loss: 0.2469 \t\n",
      "Iteration: 356 \t, Train loss: 0.0715 \t, Test loss: 0.2468 \t\n",
      "Iteration: 357 \t, Train loss: 0.0713 \t, Test loss: 0.2466 \t\n",
      "Iteration: 358 \t, Train loss: 0.0711 \t, Test loss: 0.2464 \t\n",
      "Iteration: 359 \t, Train loss: 0.0709 \t, Test loss: 0.2463 \t\n",
      "Iteration: 360 \t, Train loss: 0.0707 \t, Test loss: 0.2461 \t\n",
      "Iteration: 361 \t, Train loss: 0.0705 \t, Test loss: 0.2460 \t\n",
      "Iteration: 362 \t, Train loss: 0.0703 \t, Test loss: 0.2458 \t\n",
      "Iteration: 363 \t, Train loss: 0.0701 \t, Test loss: 0.2457 \t\n",
      "Iteration: 364 \t, Train loss: 0.0699 \t, Test loss: 0.2455 \t\n",
      "Iteration: 365 \t, Train loss: 0.0698 \t, Test loss: 0.2453 \t\n",
      "Iteration: 366 \t, Train loss: 0.0695 \t, Test loss: 0.2453 \t\n",
      "Iteration: 367 \t, Train loss: 0.0694 \t, Test loss: 0.2453 \t\n",
      "Iteration: 368 \t, Train loss: 0.0691 \t, Test loss: 0.2451 \t\n",
      "Iteration: 369 \t, Train loss: 0.0690 \t, Test loss: 0.2451 \t\n",
      "Iteration: 370 \t, Train loss: 0.0688 \t, Test loss: 0.2451 \t\n",
      "Iteration: 371 \t, Train loss: 0.0686 \t, Test loss: 0.2450 \t\n",
      "Iteration: 372 \t, Train loss: 0.0684 \t, Test loss: 0.2448 \t\n",
      "Iteration: 373 \t, Train loss: 0.0683 \t, Test loss: 0.2448 \t\n",
      "Iteration: 374 \t, Train loss: 0.0681 \t, Test loss: 0.2446 \t\n",
      "Iteration: 375 \t, Train loss: 0.0679 \t, Test loss: 0.2447 \t\n",
      "Iteration: 376 \t, Train loss: 0.0678 \t, Test loss: 0.2446 \t\n",
      "Iteration: 377 \t, Train loss: 0.0676 \t, Test loss: 0.2446 \t\n",
      "Iteration: 378 \t, Train loss: 0.0674 \t, Test loss: 0.2441 \t\n",
      "Iteration: 379 \t, Train loss: 0.0672 \t, Test loss: 0.2441 \t\n",
      "Iteration: 380 \t, Train loss: 0.0670 \t, Test loss: 0.2440 \t\n",
      "Iteration: 381 \t, Train loss: 0.0668 \t, Test loss: 0.2439 \t\n",
      "Iteration: 382 \t, Train loss: 0.0667 \t, Test loss: 0.2437 \t\n",
      "Iteration: 383 \t, Train loss: 0.0665 \t, Test loss: 0.2434 \t\n",
      "Iteration: 384 \t, Train loss: 0.0663 \t, Test loss: 0.2431 \t\n",
      "Iteration: 385 \t, Train loss: 0.0661 \t, Test loss: 0.2428 \t\n",
      "Iteration: 386 \t, Train loss: 0.0659 \t, Test loss: 0.2428 \t\n",
      "Iteration: 387 \t, Train loss: 0.0658 \t, Test loss: 0.2428 \t\n",
      "Iteration: 388 \t, Train loss: 0.0656 \t, Test loss: 0.2427 \t\n",
      "Iteration: 389 \t, Train loss: 0.0655 \t, Test loss: 0.2427 \t\n",
      "Iteration: 390 \t, Train loss: 0.0653 \t, Test loss: 0.2427 \t\n",
      "Iteration: 391 \t, Train loss: 0.0651 \t, Test loss: 0.2425 \t\n",
      "Iteration: 392 \t, Train loss: 0.0649 \t, Test loss: 0.2424 \t\n",
      "Iteration: 393 \t, Train loss: 0.0647 \t, Test loss: 0.2421 \t\n",
      "Iteration: 394 \t, Train loss: 0.0646 \t, Test loss: 0.2420 \t\n",
      "Iteration: 395 \t, Train loss: 0.0644 \t, Test loss: 0.2420 \t\n",
      "Iteration: 396 \t, Train loss: 0.0643 \t, Test loss: 0.2420 \t\n",
      "Iteration: 397 \t, Train loss: 0.0641 \t, Test loss: 0.2421 \t\n",
      "Iteration: 398 \t, Train loss: 0.0640 \t, Test loss: 0.2420 \t\n",
      "Iteration: 399 \t, Train loss: 0.0639 \t, Test loss: 0.2418 \t\n",
      "0.962211614956\n"
     ]
    }
   ],
   "source": [
    "clf_bag_5 = GradientBoosting()\n",
    "clf_bag_5.fit(X_train, Y_train, _basic_model=Bagging,\n",
    "            _args = {},\n",
    "            _X_val=X_test, _Y_val=Y_test, _n_estimators = 400, _learning_rate=0.1, _verbose = 1)\n",
    "print accuracy_score(clf_bag_5.predict(X_test).round(), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t, Train loss: 0.0637 \t, Test loss: 0.2415 \t\n",
      "Iteration: 1 \t, Train loss: 0.0635 \t, Test loss: 0.2413 \t\n",
      "Iteration: 2 \t, Train loss: 0.0634 \t, Test loss: 0.2415 \t\n",
      "Iteration: 3 \t, Train loss: 0.0632 \t, Test loss: 0.2414 \t\n",
      "Iteration: 4 \t, Train loss: 0.0631 \t, Test loss: 0.2413 \t\n",
      "Iteration: 5 \t, Train loss: 0.0629 \t, Test loss: 0.2409 \t\n",
      "Iteration: 6 \t, Train loss: 0.0627 \t, Test loss: 0.2409 \t\n",
      "Iteration: 7 \t, Train loss: 0.0626 \t, Test loss: 0.2407 \t\n",
      "Iteration: 8 \t, Train loss: 0.0624 \t, Test loss: 0.2406 \t\n",
      "Iteration: 9 \t, Train loss: 0.0623 \t, Test loss: 0.2404 \t\n",
      "Iteration: 10 \t, Train loss: 0.0621 \t, Test loss: 0.2402 \t\n",
      "Iteration: 11 \t, Train loss: 0.0620 \t, Test loss: 0.2400 \t\n",
      "Iteration: 12 \t, Train loss: 0.0618 \t, Test loss: 0.2401 \t\n",
      "Iteration: 13 \t, Train loss: 0.0617 \t, Test loss: 0.2400 \t\n",
      "Iteration: 14 \t, Train loss: 0.0615 \t, Test loss: 0.2400 \t\n",
      "Iteration: 15 \t, Train loss: 0.0613 \t, Test loss: 0.2396 \t\n",
      "Iteration: 16 \t, Train loss: 0.0612 \t, Test loss: 0.2395 \t\n",
      "Iteration: 17 \t, Train loss: 0.0610 \t, Test loss: 0.2395 \t\n",
      "Iteration: 18 \t, Train loss: 0.0609 \t, Test loss: 0.2394 \t\n",
      "Iteration: 19 \t, Train loss: 0.0607 \t, Test loss: 0.2391 \t\n",
      "Iteration: 20 \t, Train loss: 0.0606 \t, Test loss: 0.2388 \t\n",
      "Iteration: 21 \t, Train loss: 0.0604 \t, Test loss: 0.2387 \t\n",
      "Iteration: 22 \t, Train loss: 0.0602 \t, Test loss: 0.2385 \t\n",
      "Iteration: 23 \t, Train loss: 0.0600 \t, Test loss: 0.2383 \t\n",
      "Iteration: 24 \t, Train loss: 0.0599 \t, Test loss: 0.2382 \t\n",
      "Iteration: 25 \t, Train loss: 0.0598 \t, Test loss: 0.2379 \t\n",
      "Iteration: 26 \t, Train loss: 0.0596 \t, Test loss: 0.2378 \t\n",
      "Iteration: 27 \t, Train loss: 0.0594 \t, Test loss: 0.2375 \t\n",
      "Iteration: 28 \t, Train loss: 0.0593 \t, Test loss: 0.2372 \t\n",
      "Iteration: 29 \t, Train loss: 0.0592 \t, Test loss: 0.2370 \t\n",
      "Iteration: 30 \t, Train loss: 0.0591 \t, Test loss: 0.2369 \t\n",
      "Iteration: 31 \t, Train loss: 0.0589 \t, Test loss: 0.2367 \t\n",
      "Iteration: 32 \t, Train loss: 0.0588 \t, Test loss: 0.2367 \t\n",
      "Iteration: 33 \t, Train loss: 0.0586 \t, Test loss: 0.2367 \t\n",
      "Iteration: 34 \t, Train loss: 0.0585 \t, Test loss: 0.2366 \t\n",
      "Iteration: 35 \t, Train loss: 0.0583 \t, Test loss: 0.2368 \t\n",
      "Iteration: 36 \t, Train loss: 0.0582 \t, Test loss: 0.2367 \t\n",
      "Iteration: 37 \t, Train loss: 0.0580 \t, Test loss: 0.2363 \t\n",
      "Iteration: 38 \t, Train loss: 0.0578 \t, Test loss: 0.2362 \t\n",
      "Iteration: 39 \t, Train loss: 0.0577 \t, Test loss: 0.2359 \t\n",
      "Iteration: 40 \t, Train loss: 0.0576 \t, Test loss: 0.2359 \t\n",
      "Iteration: 41 \t, Train loss: 0.0574 \t, Test loss: 0.2357 \t\n",
      "Iteration: 42 \t, Train loss: 0.0573 \t, Test loss: 0.2358 \t\n",
      "Iteration: 43 \t, Train loss: 0.0571 \t, Test loss: 0.2356 \t\n",
      "Iteration: 44 \t, Train loss: 0.0570 \t, Test loss: 0.2356 \t\n",
      "Iteration: 45 \t, Train loss: 0.0569 \t, Test loss: 0.2354 \t\n",
      "Iteration: 46 \t, Train loss: 0.0567 \t, Test loss: 0.2352 \t\n",
      "Iteration: 47 \t, Train loss: 0.0566 \t, Test loss: 0.2351 \t\n",
      "Iteration: 48 \t, Train loss: 0.0564 \t, Test loss: 0.2350 \t\n",
      "Iteration: 49 \t, Train loss: 0.0563 \t, Test loss: 0.2350 \t\n",
      "Iteration: 50 \t, Train loss: 0.0562 \t, Test loss: 0.2346 \t\n",
      "Iteration: 51 \t, Train loss: 0.0560 \t, Test loss: 0.2345 \t\n",
      "Iteration: 52 \t, Train loss: 0.0559 \t, Test loss: 0.2344 \t\n",
      "Iteration: 53 \t, Train loss: 0.0557 \t, Test loss: 0.2342 \t\n",
      "Iteration: 54 \t, Train loss: 0.0556 \t, Test loss: 0.2342 \t\n",
      "Iteration: 55 \t, Train loss: 0.0555 \t, Test loss: 0.2342 \t\n",
      "Iteration: 56 \t, Train loss: 0.0553 \t, Test loss: 0.2342 \t\n",
      "Iteration: 57 \t, Train loss: 0.0551 \t, Test loss: 0.2341 \t\n",
      "Iteration: 58 \t, Train loss: 0.0550 \t, Test loss: 0.2341 \t\n",
      "Iteration: 59 \t, Train loss: 0.0549 \t, Test loss: 0.2341 \t\n",
      "Iteration: 60 \t, Train loss: 0.0547 \t, Test loss: 0.2341 \t\n",
      "Iteration: 61 \t, Train loss: 0.0546 \t, Test loss: 0.2341 \t\n",
      "Iteration: 62 \t, Train loss: 0.0545 \t, Test loss: 0.2339 \t\n",
      "Iteration: 63 \t, Train loss: 0.0543 \t, Test loss: 0.2340 \t\n",
      "Iteration: 64 \t, Train loss: 0.0542 \t, Test loss: 0.2338 \t\n",
      "Iteration: 65 \t, Train loss: 0.0541 \t, Test loss: 0.2336 \t\n",
      "Iteration: 66 \t, Train loss: 0.0539 \t, Test loss: 0.2338 \t\n",
      "Iteration: 67 \t, Train loss: 0.0537 \t, Test loss: 0.2340 \t\n",
      "Iteration: 68 \t, Train loss: 0.0536 \t, Test loss: 0.2338 \t\n",
      "Iteration: 69 \t, Train loss: 0.0535 \t, Test loss: 0.2338 \t\n",
      "Iteration: 70 \t, Train loss: 0.0533 \t, Test loss: 0.2337 \t\n",
      "Iteration: 71 \t, Train loss: 0.0532 \t, Test loss: 0.2338 \t\n",
      "Iteration: 72 \t, Train loss: 0.0531 \t, Test loss: 0.2337 \t\n",
      "Iteration: 73 \t, Train loss: 0.0529 \t, Test loss: 0.2336 \t\n",
      "Iteration: 74 \t, Train loss: 0.0528 \t, Test loss: 0.2335 \t\n",
      "Iteration: 75 \t, Train loss: 0.0527 \t, Test loss: 0.2333 \t\n",
      "Iteration: 76 \t, Train loss: 0.0526 \t, Test loss: 0.2335 \t\n",
      "Iteration: 77 \t, Train loss: 0.0524 \t, Test loss: 0.2337 \t\n",
      "Iteration: 78 \t, Train loss: 0.0523 \t, Test loss: 0.2335 \t\n",
      "Iteration: 79 \t, Train loss: 0.0521 \t, Test loss: 0.2335 \t\n",
      "Iteration: 80 \t, Train loss: 0.0520 \t, Test loss: 0.2335 \t\n",
      "Iteration: 81 \t, Train loss: 0.0519 \t, Test loss: 0.2334 \t\n",
      "Iteration: 82 \t, Train loss: 0.0517 \t, Test loss: 0.2334 \t\n",
      "Iteration: 83 \t, Train loss: 0.0517 \t, Test loss: 0.2332 \t\n",
      "Iteration: 84 \t, Train loss: 0.0515 \t, Test loss: 0.2330 \t\n",
      "Iteration: 85 \t, Train loss: 0.0514 \t, Test loss: 0.2328 \t\n",
      "Iteration: 86 \t, Train loss: 0.0512 \t, Test loss: 0.2326 \t\n",
      "Iteration: 87 \t, Train loss: 0.0511 \t, Test loss: 0.2326 \t\n",
      "Iteration: 88 \t, Train loss: 0.0510 \t, Test loss: 0.2326 \t\n",
      "Iteration: 89 \t, Train loss: 0.0508 \t, Test loss: 0.2325 \t\n",
      "Iteration: 90 \t, Train loss: 0.0507 \t, Test loss: 0.2326 \t\n",
      "Iteration: 91 \t, Train loss: 0.0505 \t, Test loss: 0.2325 \t\n",
      "Iteration: 92 \t, Train loss: 0.0504 \t, Test loss: 0.2325 \t\n",
      "Iteration: 93 \t, Train loss: 0.0503 \t, Test loss: 0.2325 \t\n",
      "Iteration: 94 \t, Train loss: 0.0502 \t, Test loss: 0.2324 \t\n",
      "Iteration: 95 \t, Train loss: 0.0500 \t, Test loss: 0.2323 \t\n",
      "Iteration: 96 \t, Train loss: 0.0499 \t, Test loss: 0.2322 \t\n",
      "Iteration: 97 \t, Train loss: 0.0498 \t, Test loss: 0.2322 \t\n",
      "Iteration: 98 \t, Train loss: 0.0497 \t, Test loss: 0.2322 \t\n",
      "Iteration: 99 \t, Train loss: 0.0495 \t, Test loss: 0.2320 \t\n",
      "Iteration: 100 \t, Train loss: 0.0494 \t, Test loss: 0.2320 \t\n",
      "Iteration: 101 \t, Train loss: 0.0493 \t, Test loss: 0.2319 \t\n",
      "Iteration: 102 \t, Train loss: 0.0492 \t, Test loss: 0.2318 \t\n",
      "Iteration: 103 \t, Train loss: 0.0491 \t, Test loss: 0.2318 \t\n",
      "Iteration: 104 \t, Train loss: 0.0490 \t, Test loss: 0.2317 \t\n",
      "Iteration: 105 \t, Train loss: 0.0488 \t, Test loss: 0.2314 \t\n",
      "Iteration: 106 \t, Train loss: 0.0487 \t, Test loss: 0.2314 \t\n",
      "Iteration: 107 \t, Train loss: 0.0486 \t, Test loss: 0.2314 \t\n",
      "Iteration: 108 \t, Train loss: 0.0485 \t, Test loss: 0.2315 \t\n",
      "Iteration: 109 \t, Train loss: 0.0484 \t, Test loss: 0.2313 \t\n",
      "Iteration: 110 \t, Train loss: 0.0482 \t, Test loss: 0.2312 \t\n",
      "Iteration: 111 \t, Train loss: 0.0481 \t, Test loss: 0.2311 \t\n",
      "Iteration: 112 \t, Train loss: 0.0479 \t, Test loss: 0.2310 \t\n",
      "Iteration: 113 \t, Train loss: 0.0478 \t, Test loss: 0.2308 \t\n",
      "Iteration: 114 \t, Train loss: 0.0477 \t, Test loss: 0.2307 \t\n",
      "Iteration: 115 \t, Train loss: 0.0476 \t, Test loss: 0.2304 \t\n",
      "Iteration: 116 \t, Train loss: 0.0475 \t, Test loss: 0.2304 \t\n",
      "Iteration: 117 \t, Train loss: 0.0474 \t, Test loss: 0.2304 \t\n",
      "Iteration: 118 \t, Train loss: 0.0472 \t, Test loss: 0.2302 \t\n",
      "Iteration: 119 \t, Train loss: 0.0471 \t, Test loss: 0.2300 \t\n",
      "Iteration: 120 \t, Train loss: 0.0470 \t, Test loss: 0.2299 \t\n",
      "Iteration: 121 \t, Train loss: 0.0469 \t, Test loss: 0.2298 \t\n",
      "Iteration: 122 \t, Train loss: 0.0468 \t, Test loss: 0.2296 \t\n",
      "Iteration: 123 \t, Train loss: 0.0467 \t, Test loss: 0.2297 \t\n",
      "Iteration: 124 \t, Train loss: 0.0466 \t, Test loss: 0.2296 \t\n",
      "Iteration: 125 \t, Train loss: 0.0464 \t, Test loss: 0.2295 \t\n",
      "Iteration: 126 \t, Train loss: 0.0463 \t, Test loss: 0.2294 \t\n",
      "Iteration: 127 \t, Train loss: 0.0462 \t, Test loss: 0.2294 \t\n",
      "Iteration: 128 \t, Train loss: 0.0460 \t, Test loss: 0.2295 \t\n",
      "Iteration: 129 \t, Train loss: 0.0459 \t, Test loss: 0.2292 \t\n",
      "Iteration: 130 \t, Train loss: 0.0458 \t, Test loss: 0.2292 \t\n",
      "Iteration: 131 \t, Train loss: 0.0457 \t, Test loss: 0.2291 \t\n",
      "Iteration: 132 \t, Train loss: 0.0456 \t, Test loss: 0.2290 \t\n",
      "Iteration: 133 \t, Train loss: 0.0455 \t, Test loss: 0.2290 \t\n",
      "Iteration: 134 \t, Train loss: 0.0454 \t, Test loss: 0.2290 \t\n",
      "Iteration: 135 \t, Train loss: 0.0452 \t, Test loss: 0.2288 \t\n",
      "Iteration: 136 \t, Train loss: 0.0451 \t, Test loss: 0.2287 \t\n",
      "Iteration: 137 \t, Train loss: 0.0450 \t, Test loss: 0.2286 \t\n",
      "Iteration: 138 \t, Train loss: 0.0449 \t, Test loss: 0.2284 \t\n",
      "Iteration: 139 \t, Train loss: 0.0448 \t, Test loss: 0.2283 \t\n",
      "Iteration: 140 \t, Train loss: 0.0447 \t, Test loss: 0.2282 \t\n",
      "Iteration: 141 \t, Train loss: 0.0445 \t, Test loss: 0.2281 \t\n",
      "Iteration: 142 \t, Train loss: 0.0444 \t, Test loss: 0.2279 \t\n",
      "Iteration: 143 \t, Train loss: 0.0443 \t, Test loss: 0.2278 \t\n",
      "Iteration: 144 \t, Train loss: 0.0442 \t, Test loss: 0.2275 \t\n",
      "Iteration: 145 \t, Train loss: 0.0441 \t, Test loss: 0.2276 \t\n",
      "Iteration: 146 \t, Train loss: 0.0440 \t, Test loss: 0.2275 \t\n",
      "Iteration: 147 \t, Train loss: 0.0439 \t, Test loss: 0.2277 \t\n",
      "Iteration: 148 \t, Train loss: 0.0438 \t, Test loss: 0.2275 \t\n",
      "Iteration: 149 \t, Train loss: 0.0437 \t, Test loss: 0.2274 \t\n",
      "Iteration: 150 \t, Train loss: 0.0436 \t, Test loss: 0.2273 \t\n",
      "Iteration: 151 \t, Train loss: 0.0435 \t, Test loss: 0.2274 \t\n",
      "Iteration: 152 \t, Train loss: 0.0434 \t, Test loss: 0.2273 \t\n",
      "Iteration: 153 \t, Train loss: 0.0433 \t, Test loss: 0.2273 \t\n",
      "Iteration: 154 \t, Train loss: 0.0431 \t, Test loss: 0.2271 \t\n",
      "Iteration: 155 \t, Train loss: 0.0430 \t, Test loss: 0.2270 \t\n",
      "Iteration: 156 \t, Train loss: 0.0429 \t, Test loss: 0.2270 \t\n",
      "Iteration: 157 \t, Train loss: 0.0428 \t, Test loss: 0.2269 \t\n",
      "Iteration: 158 \t, Train loss: 0.0427 \t, Test loss: 0.2269 \t\n",
      "Iteration: 159 \t, Train loss: 0.0426 \t, Test loss: 0.2269 \t\n",
      "Iteration: 160 \t, Train loss: 0.0425 \t, Test loss: 0.2271 \t\n",
      "Iteration: 161 \t, Train loss: 0.0424 \t, Test loss: 0.2270 \t\n",
      "Iteration: 162 \t, Train loss: 0.0422 \t, Test loss: 0.2270 \t\n",
      "Iteration: 163 \t, Train loss: 0.0422 \t, Test loss: 0.2268 \t\n",
      "Iteration: 164 \t, Train loss: 0.0421 \t, Test loss: 0.2270 \t\n",
      "Iteration: 165 \t, Train loss: 0.0420 \t, Test loss: 0.2269 \t\n",
      "Iteration: 166 \t, Train loss: 0.0418 \t, Test loss: 0.2268 \t\n",
      "Iteration: 167 \t, Train loss: 0.0418 \t, Test loss: 0.2268 \t\n",
      "Iteration: 168 \t, Train loss: 0.0417 \t, Test loss: 0.2268 \t\n",
      "Iteration: 169 \t, Train loss: 0.0415 \t, Test loss: 0.2270 \t\n",
      "Iteration: 170 \t, Train loss: 0.0415 \t, Test loss: 0.2269 \t\n",
      "Iteration: 171 \t, Train loss: 0.0414 \t, Test loss: 0.2268 \t\n",
      "Iteration: 172 \t, Train loss: 0.0413 \t, Test loss: 0.2267 \t\n",
      "Iteration: 173 \t, Train loss: 0.0411 \t, Test loss: 0.2265 \t\n",
      "Iteration: 174 \t, Train loss: 0.0410 \t, Test loss: 0.2263 \t\n",
      "Iteration: 175 \t, Train loss: 0.0409 \t, Test loss: 0.2264 \t\n",
      "Iteration: 176 \t, Train loss: 0.0408 \t, Test loss: 0.2263 \t\n",
      "Iteration: 177 \t, Train loss: 0.0408 \t, Test loss: 0.2264 \t\n",
      "Iteration: 178 \t, Train loss: 0.0407 \t, Test loss: 0.2265 \t\n",
      "Iteration: 179 \t, Train loss: 0.0406 \t, Test loss: 0.2264 \t\n",
      "Iteration: 180 \t, Train loss: 0.0404 \t, Test loss: 0.2263 \t\n",
      "Iteration: 181 \t, Train loss: 0.0403 \t, Test loss: 0.2262 \t\n",
      "Iteration: 182 \t, Train loss: 0.0402 \t, Test loss: 0.2260 \t\n",
      "Iteration: 183 \t, Train loss: 0.0402 \t, Test loss: 0.2261 \t\n",
      "Iteration: 184 \t, Train loss: 0.0400 \t, Test loss: 0.2260 \t\n",
      "Iteration: 185 \t, Train loss: 0.0400 \t, Test loss: 0.2258 \t\n",
      "Iteration: 186 \t, Train loss: 0.0399 \t, Test loss: 0.2258 \t\n",
      "Iteration: 187 \t, Train loss: 0.0398 \t, Test loss: 0.2255 \t\n",
      "Iteration: 188 \t, Train loss: 0.0397 \t, Test loss: 0.2255 \t\n",
      "Iteration: 189 \t, Train loss: 0.0395 \t, Test loss: 0.2252 \t\n",
      "Iteration: 190 \t, Train loss: 0.0394 \t, Test loss: 0.2252 \t\n",
      "Iteration: 191 \t, Train loss: 0.0393 \t, Test loss: 0.2250 \t\n",
      "Iteration: 192 \t, Train loss: 0.0393 \t, Test loss: 0.2249 \t\n",
      "Iteration: 193 \t, Train loss: 0.0392 \t, Test loss: 0.2249 \t\n",
      "Iteration: 194 \t, Train loss: 0.0391 \t, Test loss: 0.2247 \t\n",
      "Iteration: 195 \t, Train loss: 0.0390 \t, Test loss: 0.2246 \t\n",
      "Iteration: 196 \t, Train loss: 0.0389 \t, Test loss: 0.2245 \t\n",
      "Iteration: 197 \t, Train loss: 0.0388 \t, Test loss: 0.2244 \t\n",
      "Iteration: 198 \t, Train loss: 0.0387 \t, Test loss: 0.2242 \t\n",
      "Iteration: 199 \t, Train loss: 0.0386 \t, Test loss: 0.2242 \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-95d18ca52f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf_bag_5.fit(X_train, Y_train, _basic_model=Bagging,\n\u001b[1;32m      2\u001b[0m             \u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             _X_val=X_test, _Y_val=Y_test, _n_estimators = 300, _learning_rate=0.1, _verbose = 1)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_bag_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-0df8b542217d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, _X, _Y, _basic_model, _args, _args_init, _X_val, _Y_val, _n_estimators, _bag_part, _verbose, _save_scores, _learning_rate)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#save losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Y_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_verbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-0df8b542217d>\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, _X)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-406e1f4ece34>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, _X)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8bbd917d291c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, _X)\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                ):\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     def score(self, \n",
      "\u001b[0;32m<ipython-input-3-d9421fa37ec4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, _X)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0midx_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0midx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mY_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mY_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_l\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d9421fa37ec4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, _X)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0midx_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0midx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mY_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mY_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_l\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_bag_5.fit(X_train, Y_train, _basic_model=Bagging,\n",
    "            _args = {},\n",
    "            _X_val=X_test, _Y_val=Y_test, _n_estimators = 300, _learning_rate=0.1, _verbose = 1)\n",
    "print accuracy_score(clf_bag_5.predict(X_test).round(), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** График **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAJPCAYAAAA9sTYbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCHEJiEBTgghhBBCCCE2if8P0TuCPFrLMP0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1121c4410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(np.array(skl_losses_2[:600]) * 1.03, 'g')\n",
    "plt.plot([min(skl_losses_2[:600])] * 600, 'm')\n",
    "plt.plot(clf_bag_5.losses_test, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224585940711 0.224185814781\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print min(skl_losses_2), min(clf_bag_5.losses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss(y, predict):\n",
    "    f = 1 / (1 + np.exp(-predict))\n",
    "    return np.mean(- y * np.log(f) - (1 - y) * np.log(1 - f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
